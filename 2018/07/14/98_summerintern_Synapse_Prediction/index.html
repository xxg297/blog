<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/blog/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/blog/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="google-site-verification" content="google5b248f7b86cbcee5.html" />














  
  
  <link href="/blog/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/blog/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/blog/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/blog/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="project,neural science,summer intern,connectomics,computational neural science,deep learning,computer vision,Jeff Lichtman," />





  <link rel="alternate" href="/blog/atom.xml" title="WonderLand" type="application/atom+xml" />






<meta name="description" content="It is part of my computational task during my summer intern in Lichtman Lab and Hanspiter Lab. It is part of the big synapse project. Also the challenge 2 of CREMI We now rank No.1 in the CREMI contes">
<meta name="keywords" content="project,neural science,summer intern,connectomics,computational neural science,deep learning,computer vision,Jeff Lichtman">
<meta property="og:type" content="article">
<meta property="og:title" content="Synapse Prediction Project">
<meta property="og:url" content="https://www.cmwonderland.com/blog/2018/07/14/98_summerintern_Synapse_Prediction/index.html">
<meta property="og:site_name" content="WonderLand">
<meta property="og:description" content="It is part of my computational task during my summer intern in Lichtman Lab and Hanspiter Lab. It is part of the big synapse project. Also the challenge 2 of CREMI We now rank No.1 in the CREMI contes">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://i2.tiimg.com/640680/aac9181df1496b48.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/03763aade56aca61.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/a3694f6e59e4a242.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/163718480760fffd.png">
<meta property="og:image" content="http://i1.fuimg.com/640680/b230e7beb1ffb4fd.png">
<meta property="og:image" content="http://i1.fuimg.com/640680/8f09339677f17d82.png">
<meta property="og:image" content="http://i1.fuimg.com/640680/b57e8e884c754591.png">
<meta property="og:image" content="http://i1.fuimg.com/640680/3dfea030bf017168.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/52858efa5d322afa.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/58f54732f92776ef.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/2be847081da6e223.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/64061355143fac3a.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/5271eb263cb9e565.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/a41fb440d8d1c617.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/132ddef47af261fc.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/208732c8803ea2b3.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/206cd5295b80d561.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/ceea6995778ee50a.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/b793b22de5ed6051.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/d196b3bb76ababaa.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/cbdbb1c2f4192ada.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/14a4604e6910d2ef.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/45a62036466fb811.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/7597c15cb6c70bd5.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/0fefcfc0276481ba.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/b88ca29cc508e738.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/d898e30f03ec6e90.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/a077144bab1af22e.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/1f07ed5887f5112b.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/24b6323ecbacadcb.png">
<meta property="og:image" content="http://i1.fuimg.com/640680/1b36249fa6f56a59.png">
<meta property="og:image" content="http://i1.fuimg.com/640680/3d5fe582cfbd9d77.png">
<meta property="og:updated_time" content="2019-04-23T13:07:13.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Synapse Prediction Project">
<meta name="twitter:description" content="It is part of my computational task during my summer intern in Lichtman Lab and Hanspiter Lab. It is part of the big synapse project. Also the challenge 2 of CREMI We now rank No.1 in the CREMI contes">
<meta name="twitter:image" content="http://i2.tiimg.com/640680/aac9181df1496b48.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/blog/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://www.cmwonderland.com/blog/2018/07/14/98_summerintern_Synapse_Prediction/"/>





  <title>Synapse Prediction Project | WonderLand</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?6656499bfc0e07b4e20ee4975eb85f31";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <a href="https://github.com/james20141606"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_white_ffffff.png" alt="Fork me on GitHub"></a>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/blog/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">WonderLand</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Somnium & Somniator</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/blog/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/blog/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/blog/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/blog/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/blog/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.cmwonderland.com/blog/blog/2018/07/14/98_summerintern_Synapse_Prediction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="James Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/blog/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WonderLand">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Synapse Prediction Project</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-14T22:50:06-04:00">
                2018-07-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/projects/" itemprop="url" rel="index">
                    <span itemprop="name">projects</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/blog/2018/07/14/98_summerintern_Synapse_Prediction/" class="leancloud_visitors" data-flag-title="Synapse Prediction Project">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  7,268
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  45
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>It is part of my computational task during my summer intern in <a href="https://lichtmanlab.fas.harvard.edu/" target="_blank" rel="noopener">Lichtman Lab</a> and <a href="https://vcg.seas.harvard.edu/people" target="_blank" rel="noopener">Hanspiter Lab</a>.</p>
<p>It is part of the big synapse project. Also the challenge 2 of <a href="https://cremi.org" target="_blank" rel="noopener">CREMI</a></p>
<p>We now rank <strong>No.1</strong> in the <a href="https://cremi.org" target="_blank" rel="noopener">CREMI contest</a>. And we will submit a paper to CVPR this November.</p>
<p>For <strong>whole work summary</strong> please <a href="https://www.cmwonderland.com/blog/2018/09/12/100_summer_intern/">see here</a></p>


	<div class="row">
		<iframe src="https://drive.google.com/file/d/1XyEPj9r7p8VNk5nLlLIPNhZjuDHu2KTY/preview" style="width:100%; height:550px"></iframe>
	</div>



<p>Also I finished another NMJ project during summer intern in <a href="https://lichtmanlab.fas.harvard.edu/" target="_blank" rel="noopener">Lichtman Lab</a> </p>
<h1 id="Codes"><a href="#Codes" class="headerlink" title="Codes"></a>Codes</h1><ul>
<li><a href="https://github.com/james20141606/Summer_Intern/tree/master/synapse_prediction" target="_blank" rel="noopener">Summer_Intern/synaptic_partner at master · james20141606/Summer_Intern · GitHub</a></li>
<li><a href="https://github.com/james20141606/EM-network" target="_blank" rel="noopener">Synapse polarity</a></li>
</ul>
<a id="more"></a>
<h1 id="weekly-report"><a href="#weekly-report" class="headerlink" title="weekly report"></a>weekly report</h1><h2 id="First"><a href="#First" class="headerlink" title="First"></a>First</h2>

	<div class="row">
		<iframe src="https://drive.google.com/file/d/1bmWX9M1aTgOw7YB9xrnUNynWfxuoa_Rz/preview" style="width:100%; height:550px"></iframe>
	</div>



<h2 id="Second"><a href="#Second" class="headerlink" title="Second"></a>Second</h2>

	<div class="row">
		<iframe src="https://drive.google.com/file/d/1OOaFajkLcwQBEf1XQuEIYqFAkl9psPrt/preview" style="width:100%; height:550px"></iframe>
	</div>



<h2 id="Third"><a href="#Third" class="headerlink" title="Third"></a>Third</h2>

	<div class="row">
		<iframe src="https://drive.google.com/file/d/1We4g3Ltd2gqzmICoLtKFKsL-2zP2BVeV/preview" style="width:100%; height:550px"></iframe>
	</div>



<h2 id="Fourth"><a href="#Fourth" class="headerlink" title="Fourth"></a>Fourth</h2>

	<div class="row">
		<iframe src="https://drive.google.com/file/d/19zhoBM6GP94a-bNj7bFIZdExC0x6yw_2/preview" style="width:100%; height:550px"></iframe>
	</div>



<hr>
<h1 id="First-two-weeks"><a href="#First-two-weeks" class="headerlink" title="First two weeks"></a>First two weeks</h1><h2 id="summarize-and-rewrite-some-data-augmentation-repo"><a href="#summarize-and-rewrite-some-data-augmentation-repo" class="headerlink" title="summarize and rewrite some data augmentation repo"></a>summarize and rewrite some data augmentation repo</h2><p>The three main repos are gunpowder from funke lab, EM-data, EM-seglib from Sebastian lab.</p>
<p>Gunpowder is quite complicated since it includes a whole pipeline of data preprocessing. It defines some batch provider and batch filter at first, making it harder to understand the data augmentation steps in the middle. Since it is written in python2 and designed for caffe, I rewrite and summarize, compare the gunpowder’s four augmentation methods with Sebastian’s codes.</p>
<p>Funke said in his paper about CREMI challenge 2 that data augmentation is the most important steps in the whole pipeline. I rewrite the four kinds of data augmentation methods combining Funkey and Sebastian’s codes.<br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/jupyter/gunpowder.ipynb" target="_blank" rel="noopener">gunpowder</a><br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/jupyter/gunpowder_cremi.ipynb" target="_blank" rel="noopener">gunpowder on cremi</a></p>
<ul>
<li>simple augmentation</li>
<li>intensity augment</li>
<li>ElasticAugment</li>
<li>DefectAugment</li>
</ul>
<h2 id="simple-augmentation"><a href="#simple-augmentation" class="headerlink" title="simple augmentation"></a>simple augmentation</h2><p>class gunpowder.SimpleAugment(mirror_only=None, transpose_only=None)<br>Randomly mirror and transpose all Arrays and Points in a batch.</p>
<p>simple augment can be achieved by EM-segLib/em_segLib/transform.py!<br>in this repo, only transpose_only_xy=True is used!</p>
<h2 id="intensity-augment"><a href="#intensity-augment" class="headerlink" title="intensity augment"></a>intensity augment</h2><p>class gunpowder.IntensityAugment(array, scale_min, scale_max, shift_min, shift_max, z_section_wise=False)<br>Randomly scale and shift the values of an intensity array.</p>
<ul>
<li>array (ArrayKey) – The intensity array to modify.</li>
<li>scale_min (float) –</li>
<li>scale_max (float) –</li>
<li>shift_min (float) –</li>
<li>shift_max (float) –<br>The min and max of the uniformly randomly drawn scaling and shifting values for the intensity augmentation. Intensities are changed as:</li>
</ul>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">a</span> = <span class="selector-tag">a</span>.mean() + (a-<span class="selector-tag">a</span>.mean())*scale + shift</span><br></pre></td></tr></table></figure>
<ul>
<li>z_section_wise (bool) – Perform the augmentation z-section wise. Requires 3D arrays and assumes that z is the first dimension.</li>
</ul>
<h3 id="Randomly-scale-and-shift-the-values-of-an-intensity-array，"><a href="#Randomly-scale-and-shift-the-values-of-an-intensity-array，" class="headerlink" title="Randomly scale and shift the values of an intensity array，"></a>Randomly scale and shift the values of an intensity array，</h3><ul>
<li>can do z axis sections augmentation，first dim should be z</li>
<li>normalized array desired</li>
<li>set scale and shift’s biggest and smallest value</li>
</ul>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np<span class="selector-class">.random</span><span class="selector-class">.uniform</span>(low=self<span class="selector-class">.shift_min</span>, high=self.shift_max))</span><br></pre></td></tr></table></figure>
<p>Return scale and shift value</p>
<ul>
<li>for each array: a.mean() + (a-a.mean())*scale + shift</li>
<li>np.clip(0,1)</li>
</ul>
<h3 id="similar-implementation"><a href="#similar-implementation" class="headerlink" title="similar implementation!"></a>similar implementation!</h3><ul>
<li>scale is similar to DataProvider/python/data_augmentation.py class GreyAugment(DataAugment)!</li>
<li>DataProvider/python/data_augmentation.py class GreyAugment(DataAugment)<strong>may be better</strong>：</li>
</ul>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">img</span> *= <span class="number">1</span> + (np<span class="selector-class">.random</span><span class="selector-class">.rand</span>() - <span class="number">0.5</span>)*self.CONTRAST_FACTOR</span><br><span class="line"><span class="selector-tag">img</span> += (np<span class="selector-class">.random</span><span class="selector-class">.rand</span>() - <span class="number">0.5</span>)*self.BRIGHTNESS_FACTOR</span><br><span class="line"><span class="selector-tag">img</span> = np.<span class="attribute">clip</span>(img, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"><span class="selector-tag">img</span> **= <span class="number">2.0</span>**(np<span class="selector-class">.random</span><span class="selector-class">.rand</span>()*<span class="number">2</span> - <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>it borrows from (<a href="http://elektronn.org/).ELEKTRONN" target="_blank" rel="noopener">http://elektronn.org/).ELEKTRONN</a> is used for 2D/3D large scale image. Also used for segmentation</li>
</ul>
<h2 id="ElasticAugment"><a href="#ElasticAugment" class="headerlink" title="ElasticAugment"></a>ElasticAugment</h2><p>The author used ElasticAugment([4,40,40], [0,2,2], [0,math.pi/2.0], prob_slip=0.05,prob_shift=0.05,max_misalign=25)</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class gunpowder.ElasticAugment(control_point_spacing, jitter_sigma, rotation_interval, <span class="attribute">prob_slip</span>=0, <span class="attribute">prob_shift</span>=0, <span class="attribute">max_misalign</span>=0, <span class="attribute">subsample</span>=1)</span><br></pre></td></tr></table></figure>
<ul>
<li>reshape array data into (channels,) + spatial dims</li>
<li>first  <strong>create_identity_transformation</strong><ul>
<li>create_identity_transformation from funkey another repo augment，create_identity_transformation, channel change to three , use np.meshgrid increase two channels</li>
</ul>
</li>
<li>if sum(jitter_sigma) &gt; 0: <strong>create_elastic_transformation</strong></li>
<li><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">augment.create_elastic_transformation(</span><br><span class="line">                    target_shape,</span><br><span class="line">                    self<span class="selector-class">.control_point_spacing</span>,</span><br><span class="line">                    self<span class="selector-class">.jitter_sigma</span>,</span><br><span class="line">                    subsample=self.subsample)</span><br></pre></td></tr></table></figure>
</li>
<li><p>first get control_point_offsets，the interpolation to upscale，generate 3 channel images</p>
</li>
<li><p>then by rotation_interval [0,math.pi/2.0], rotation_start = rotation_interval[0], rotation_max_amount = rotation_interval[1] - rotation_interval[0]</p>
<p>  rotation = random.random()*self.rotation_max_amount + self.rotation_start(less than 90)</p>
</li>
</ul>
<p>If rotation&gt;0,do <strong>create_rotation_transformation</strong></p>
<ul>
<li>then if prob_slip + prob_shift &gt; 0，做<strong>__misalign(transformation)</strong></li>
</ul>
<p>According to thres to do randomly shift by section</p>
<ul>
<li><p>at last if subsample &gt;1 before elastic augmentation do subsampling to speed up elasticaugment after augmentation then do upscale</p>
<p>  Instead of creating an elastic transformation on the full<br>  resolution, create one subsampled by the given factor, and linearly<br>  interpolate to obtain the full resolution transformation. This can<br>  significantly speed up this node, at the expense of having visible<br>  piecewise linear deformations for large factors. Usually, a factor<br>  of 4 can savely by used without noticable changes. However, the<br>  default is 1 (i.e., no subsampling).</p>
</li>
</ul>
<h2 id="DefectAugment"><a href="#DefectAugment" class="headerlink" title="DefectAugment"></a>DefectAugment</h2><p>class gunpowder.DefectAugment(intensities, prob_missing=0.05, prob_low_contrast=0.05, prob_artifact=0.0, prob_deform=0.0, contrast_scale=0.1, artifact_source=None, artifacts=None, artifacts_mask=None, deformation_strength=20, axis=0)[source]</p>
<p>Augment intensity arrays section-wise with artifacts like missing sections, low-contrast sections, by blending in artifacts drawn from a separate source, or by deforming a section.</p>
<ul>
<li>intensities (ArrayKey) – The key of the array of intensities to modify.</li>
<li>prob_missing (float) –</li>
<li>prob_low_contrast (float) –</li>
<li>prob_artifact (float) –</li>
<li>prob_deform (float) – Probabilities of having a missing section, low-contrast section, an artifact (see param artifact_source) or a deformed slice. The sum should not exceed 1. Values in missing sections will be set to 0.<br>contrast_scale (float, optional) – By how much to scale the intensities for a low-contrast section, used if prob_low_contrast &gt; 0.</li>
<li><p>(class (artifact_source) – BatchProvider, optional):A gunpowder batch provider that delivers intensities (via ArrayKey artifacts) and an alpha mask (via ArrayKey artifacts_mask), used if prob_artifact &gt; 0.</p>
</li>
<li><p>artifacts (ArrayKey, optional) – The key to query artifact_source for to get the intensities of the artifacts.</p>
</li>
<li>artifacts_mask (ArrayKey, optional) – The key to query artifact_source for to get the alpha mask of the artifacts to blend them with intensities.</li>
<li>deformation_strength (int, optional) – Strength of the slice deformation in voxels, used if prob_deform &gt; 0. The deformation models a fold by shifting the section contents towards a randomly oriented line in the section. The line itself will be drawn with a value of 0.</li>
<li>axis (int, optional) – Along which axis sections are cut.</li>
</ul>
<p>From a special artifect source read data and defectaugment</p>
<figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">artifact_source = (</span><br><span class="line">        Hdf5Source(</span><br><span class="line">            'sample_ABC_padded_20160501.defects.hdf',</span><br><span class="line">            datasets = &#123;</span><br><span class="line">                ArrayKeys.RAW: 'defect_sections/raw',</span><br><span class="line">                ArrayKeys.ALPHA_MASK: 'defect_sections/mask',</span><br><span class="line">            &#125;</span><br><span class="line">        ) +</span><br><span class="line">        RandomLocation(<span class="name">min_masked=0</span>.<span class="number">05</span>, mask_array_key=ArrayKeys.ALPHA_MASK) +</span><br><span class="line">        Normalize() +</span><br><span class="line">        IntensityAugment(<span class="number">0.9</span>, <span class="number">1.1</span>, <span class="number">-0.1</span>, <span class="number">0.1</span>, z_section_wise=True) +</span><br><span class="line">        ElasticAugment([<span class="number">4</span>,<span class="number">40</span>,<span class="number">40</span>], [<span class="number">0</span>,<span class="number">2</span>,<span class="number">2</span>], [<span class="number">0</span>,math.pi/2.<span class="number">0</span>]) +</span><br><span class="line">        SimpleAugment(<span class="name">transpose_only_xy=True</span>)</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<ul>
<li><p>threshold：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">DefectAugment(</span><br><span class="line">            <span class="attribute">prob_missing</span>=0.03,</span><br><span class="line">            <span class="attribute">prob_low_contrast</span>=0.01,</span><br><span class="line">            <span class="attribute">prob_artifact</span>=0.03,</span><br><span class="line">            <span class="attribute">artifact_source</span>=artifact_source,</span><br><span class="line">            <span class="attribute">contrast_scale</span>=0.1)</span><br></pre></td></tr></table></figure>
</li>
<li><p>get missing，low_contrast, artifact, deform value    prob_missing_threshold = self.prob_missing   (0.03=0.03)<br>  prob_low_contrast_threshold = prob_missing_threshold + self.prob_low_contrast  (0.04=0.03+0.01)<br>  prob_artifact_threshold = prob_low_contrast_threshold + self.prob_artifact    (0.07=0.03+0.04)<br>  prob_deform_slice = prob_artifact_threshold + self.prob_deform   (0.07=0.07+0)</p>
</li>
<li>for each slice，generate 0-1 random value r，if：<ul>
<li>r &lt; prob_missing_threshold:  ‘zero_out’<ul>
<li>do nothing</li>
</ul>
</li>
<li>elif r &lt; prob_low_contrast_threshold:  ‘lower_contrast’<ul>
<li>mean = section.mean(), section -= mean, section *= self.contrast_scale, section += mean</li>
</ul>
</li>
<li>elif r &lt; prob_artifact_threshold:’artifact’<ul>
<li>raw.data[section_selector] = section<em>(1.0 - artifact_alpha) + artifact_raw</em>artifact_alpha</li>
<li>artifact_alpha, artifact_raw from artifact_source’s mask and raw， equals to a <strong>Alpha Blending</strong></li>
</ul>
</li>
<li>elif r &lt; prob_deform_slice: ‘deformed_slice’ if deformed slice, needs bigger upstream roi for deformed slice</li>
</ul>
</li>
</ul>
<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">section = raw.data[section_selector].squeeze()</span><br><span class="line">interpolation = 3 if self.spec[self.intensities].interpolatable <span class="keyword">else</span> 0</span><br><span class="line">flow_x, flow_y, line_mask = self.deform_slice_transformations[c]</span><br><span class="line">shape = section.shape</span><br><span class="line"><span class="comment">#做双线性插值</span></span><br><span class="line">section = map_coordinates(</span><br><span class="line">    section, (flow_y, flow_x), mode='constant', order=interpolation</span><br><span class="line">).reshape(shape)</span><br><span class="line">section = np.clip(section, 0., 1.)</span><br><span class="line">section[line_mask] = 0</span><br><span class="line">raw.data[section_selector] = section</span><br></pre></td></tr></table></figure>
<p><strong>cremi exapmle</strong><br><a href="https://github.com/funkey/gunpowder/tree/master/examples/cremi" target="_blank" rel="noopener">gunpowder/examples/cremi at master · funkey/gunpowder · GitHub</a></p>
<p>docker has problems (MALIS, pycaffe)<br>Install docker on server <a href="https://docs.docker.com/install/linux/docker-ce/ubuntu/#install-from-a-package" target="_blank" rel="noopener">Get Docker CE for Ubuntu | Docker Documentation</a></p>
<figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">docker pull funkey/gunpowder</span><br><span class="line"></span><br><span class="line">sudo docker images</span><br><span class="line">sudo docker <span class="built_in">run</span> -i -t <span class="comment">--name=chen ubuntu:latest</span></span><br><span class="line"><span class="keyword">exit</span>  </span><br><span class="line">docker start <span class="built_in">id</span> / <span class="built_in">name</span></span><br><span class="line">docker attach <span class="built_in">id</span> /<span class="built_in">name</span></span><br></pre></td></tr></table></figure>
<p>Encounter problems with installing nvidia docker and docker run.</p>
<p>Seems we should try to rewrite some codes to incorporate directly without the bothering of docker, python2, caffe, malis and other settings.</p>
<h3 id="resources"><a href="#resources" class="headerlink" title="resources"></a>resources</h3><p><a href="https://github.com/donglaiw/em-data" target="_blank" rel="noopener">GitHub - donglaiw/EM-data: dataset loader</a><br><a href="https://github.com/torms3/DataProvider/tree/refactoring/python/dataprovider" target="_blank" rel="noopener">DataProvider/python/dataprovider at refactoring · torms3/DataProvider · GitHub</a><br><a href="https://arxiv.org/abs/1706.00120" target="_blank" rel="noopener">1706.00120 Superhuman Accuracy on the SNEMI3D Connectomics Challenge</a> Sebastian group</p>
<p>Then I incorporate the data augmentation methods into synapse prediction model for further use.<br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/jupyter/augment_cremi.ipynb" target="_blank" rel="noopener">augmentation on cremi</a></p>
<h3 id="Model-test-and-redesign"><a href="#Model-test-and-redesign" class="headerlink" title="Model test and redesign"></a>Model test and redesign</h3><p>I tried zudi’s synapse prediction model using 3D U-net, since it is based on pytorch, I spent some time to read the pytorch documentation. We have discussed about the model improvement issue and I have tried to use other architecture for better prediction results.<br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/jupyter/pytorch_synapse.ipynb" target="_blank" rel="noopener">synapse prediction model</a><br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/jupyter/syn_pytorch_add_dink.ipynb" target="_blank" rel="noopener">improvement on U net</a></p>
<p>I can try a lot fine tune and redesign about U-net and 3D U-net, maybe from kaggle top solutions and github. </p>
<hr>
<h1 id="Week-3"><a href="#Week-3" class="headerlink" title="Week 3"></a>Week 3</h1><p>In week 3, apart from NMJ project, I concentrate mainly on synapse prediction project and make many progress. Since zudi has come back, it is more efficient to discuss and collaborate, we have done a lot this week.</p>
<h2 id="short-term-plan"><a href="#short-term-plan" class="headerlink" title="short term plan"></a>short term plan</h2><p>Our short term plan is adding all the new tricks (dilation CNN block from Deepglobe’s Dlink-net, DICE_BCE combined loss, all the data augmentation methods) to the model. We train the whole model for three days on all A, B, C samples. And fine tune it later for one day. Then we submit the result to see if it is better.</p>
<p>In my consideration, the previous model <strong>has a not very little gap with the state-of-art one</strong>. About one fold error score. So it is a lot for us to do. <strong>I have used dilation CNN, combined Loss, and some very useful data augmentation methods</strong> which take me many days to accomplish(All admit that proper augmentation is one of the most import procedure to achieve better results.) So this week I have read many other people’s good paper, project summary and codes in similar tasks( <strong>the dilation CNN, DICE_BCE loss and data augmentation all originate from this.</strong>) I believe there are more to implement. The state-of-art model and pipeline looks really good, so I think I should use more strategy to improve our results.</p>
<h2 id="Model-improvement-and-training"><a href="#Model-improvement-and-training" class="headerlink" title="Model improvement and training"></a>Model improvement and training</h2><h3 id="settings-and-training"><a href="#settings-and-training" class="headerlink" title="settings and training"></a>settings and training</h3><p> Since I have done several deep learning and machine learning projects(Emaize, CardiacAI, 3D CT images, Deepshape), I am quite familiar with linux, python deep learning environment and all extra settings( jupyter, TensorboardX etc). I can be quite efficient in running the previous model designed by zudi.</p>
<h4 id="training-settings"><a href="#training-settings" class="headerlink" title="training settings"></a>training settings</h4><h5 id="create-envs"><a href="#create-envs" class="headerlink" title="create envs"></a>create envs</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">conda env <span class="keyword">create</span> -f <span class="keyword">bin</span>/synapse_pytorch/envs/py3_pytorch.yml</span><br><span class="line"><span class="keyword">source</span> <span class="keyword">activate</span> py3_pytorch</span><br><span class="line"><span class="keyword">source</span> deactivate</span><br><span class="line"><span class="keyword">alias</span> act=<span class="string">'source activate py3_pytorch'</span></span><br><span class="line"><span class="keyword">alias</span> deact=<span class="string">'source deactivate'</span></span><br><span class="line">virtualenv venv</span><br></pre></td></tr></table></figure>
<h5 id="training-parameter-setting"><a href="#training-parameter-setting" class="headerlink" title="training parameter setting"></a>training parameter setting</h5><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">1</span> python3 -u bin/synapse_pytorch/train<span class="selector-class">.py</span> -t data/cremi/ -dn images/im_A_v2_200.h5@images/im_B_v2_200.h5@images/im_C_v2_200<span class="selector-class">.h5</span> -ln gt-syn/syn_A_v2_200.h5@gt-syn/syn_B_v2_200.h5@gt-syn/syn_C_v2_200<span class="selector-class">.h5</span> -o outputs/cremi0719mixloss -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">20000</span> -mi <span class="number">24</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">2</span> -c <span class="number">6</span> -<span class="selector-tag">b</span> <span class="number">2</span> -l mix</span><br><span class="line"><span class="selector-id">#b</span>:<span class="number">6</span>  try to keep gpu and batch size same</span><br></pre></td></tr></table></figure>
<h5 id="Tensorboard-monitor-setting"><a href="#Tensorboard-monitor-setting" class="headerlink" title="Tensorboard monitor setting"></a>Tensorboard monitor setting</h5><p>it is a real time monitoring</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#http://140.247.107.75:6006</span></span><br><span class="line"><span class="comment">#set locale to solve locale unsupported locale #setting problems</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">LANGUAGE</span>=en_US.UTF-8</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">LANG</span>=en_US.UTF-8</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">LC_ALL</span>=en_US.UTF-8</span><br><span class="line"><span class="comment">#tensorboard monitor dir at: synapse/runs/outputs</span></span><br><span class="line">tensorboard --logdir cremi0719</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">kill</span> jupyter and release port</span></span><br><span class="line">ps aux | grep -i notebook</span><br></pre></td></tr></table></figure>
<h3 id="network-visualization"><a href="#network-visualization" class="headerlink" title="network visualization"></a>network visualization</h3><p>I visualize our current model, it is a very big one.</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd import Variable</span><br><span class="line"><span class="keyword">from</span> torchviz import make_dot</span><br><span class="line">model = res_unet()</span><br><span class="line">model = model.<span class="keyword">to</span>(device)</span><br><span class="line">x = Variable(torch.randn(1,1,24, 256,256))#change 12 <span class="keyword">to</span> the channel number of<span class="built_in"> network </span>input</span><br><span class="line">y = model(x)</span><br><span class="line">g = make_dot(y)</span><br><span class="line">g.view()</span><br></pre></td></tr></table></figure>
<p><strong>Current model:</strong></p>
<p><img src="http://i2.tiimg.com/640680/aac9181df1496b48.png" alt="Markdown"></p>
<p>Scripts: <a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/jupyter/pytorch_synapse.ipynb" target="_blank" rel="noopener">Summer_Intern/pytorch_synapse.ipynb at master · james20141606/Summer_Intern · GitHub</a></p>
<h3 id="model-structure-and-loss-function-improvement"><a href="#model-structure-and-loss-function-improvement" class="headerlink" title="model structure and loss function improvement"></a>model structure and loss function improvement</h3><p>I read D-LinkNet: LinkNet with Pretrained Encoder and Dilated Convolution for High Resolution Satellite Imagery Road Extraction and other winners in some challenges and implement more model structure and loss function design.</p>
<h5 id="dilated-CNN-block"><a href="#dilated-CNN-block" class="headerlink" title="dilated CNN block"></a>dilated CNN block</h5><p>It can further enlarge the visual area of the model, which is helpful to learn more information efficiently. The dilation is adaptive according the the layer depth. The maximum is 8, we may change it smaller later.</p>
<h5 id="loss-function"><a href="#loss-function" class="headerlink" title="loss function"></a>loss function</h5><p>I read Deepglobe challenge’s solution and change the loss function to <strong>DICE + BCE</strong> like this:<br>P: predict result, GT: ground truth, N: batch size</p>
<script type="math/tex; mode=display">L = 1 - \frac{2 \times \sum_{i=1}^N  |P_i \cap GT_i  | }{\sum_{i=1}^N  (P_i + GT_i)} + \sum_{i=1}^N BCELoss(P_i,  GT_i)</script><p>It added a DICE part to previous BCE loss function, which is better since it is common to use DICE as loss function for U-net, the combined loss function is also used in some challenges winner.</p>
<p>loss function implementation:<br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/bin/loss.py" target="_blank" rel="noopener">Summer_Intern/loss.py at master · james20141606/Summer_Intern · GitHub</a><br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/jupyter/loss_dlink_net.ipynb" target="_blank" rel="noopener">Summer_Intern/loss_dlink_net.ipynb at master · james20141606/Summer_Intern · GitHub</a></p>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> dice_bce_loss(nn.Module):</span><br><span class="line">    def __init__(self, batch=True):</span><br><span class="line">        super(dice_bce_loss, self).__init__()</span><br><span class="line">        self.batch = batch</span><br><span class="line">        self.bce_loss = WeightedBCELoss()</span><br><span class="line"></span><br><span class="line">    def soft_dice_coeff(self, <span class="keyword">input</span>, target):</span><br><span class="line">        <span class="keyword">smooth</span> = 0.0  # may change</span><br><span class="line">        <span class="keyword">if</span> self.batch:</span><br><span class="line">            i = torch.<span class="built_in">sum</span>(target)</span><br><span class="line">            j = torch.<span class="built_in">sum</span>(<span class="keyword">input</span>)</span><br><span class="line">            intersection = torch.<span class="built_in">sum</span>(target * <span class="keyword">input</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            i = target.<span class="built_in">sum</span>(1).<span class="built_in">sum</span>(1).<span class="built_in">sum</span>(1)</span><br><span class="line">            j = <span class="keyword">input</span>.<span class="built_in">sum</span>(1).<span class="built_in">sum</span>(1).<span class="built_in">sum</span>(1)</span><br><span class="line">            intersection = (target * <span class="keyword">input</span>).<span class="built_in">sum</span>(1).<span class="built_in">sum</span>(1).<span class="built_in">sum</span>(1)</span><br><span class="line">        <span class="keyword">score</span> = (2. * intersection + <span class="keyword">smooth</span>) / (i + j + <span class="keyword">smooth</span>)</span><br><span class="line">        #<span class="keyword">score</span> = (intersection + <span class="keyword">smooth</span>) / (i + j - intersection + <span class="keyword">smooth</span>)#iou</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">score</span>.<span class="keyword">mean</span>()</span><br><span class="line"></span><br><span class="line">    def soft_dice_loss(self, <span class="keyword">input</span>, target):</span><br><span class="line">        loss = 1 - self.soft_dice_coeff(<span class="keyword">input</span>, target)</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line">    def __call__(self, <span class="keyword">input</span>, target, weight):</span><br><span class="line">        a = self.bce_loss(<span class="keyword">input</span>, target, weight)</span><br><span class="line">        b = self.soft_dice_loss(<span class="keyword">input</span>, target)</span><br><span class="line">        <span class="keyword">return</span> a + b</span><br></pre></td></tr></table></figure>
<p>I use TensorboardX to monitor the training procedure. I monitor the combined loss, DICE loss and BCE loss simultaneously. To my relief, the loss function decrease not only because BCE decrease, the DICE loss also decrease. Since 1- DICE reflect the overlap ratio of predicted and ground truth area, it means our model learns well.</p>
<p><strong>Train loss:</strong><br><img src="http://i4.fuimg.com/640680/03763aade56aca61.png" alt="Markdown"><br><strong>BCE loss:</strong><br><img src="http://i4.fuimg.com/640680/a3694f6e59e4a242.png" alt="Markdown"><br><strong>DICE loss:</strong><br><img src="http://i4.fuimg.com/640680/163718480760fffd.png" alt="Markdown"></p>
<p>We should do further improvement on loss function, BCE is divided by batch size, so we may do the same with DICE.</p>
<p>We think BCE punishes FN since we set a weight to punish it. And we think DICE is punishing FP since the remained are mainly FP, and we think it is good: our strategy is remove FN at first, then we can prune FP using some methods. So DICE loss may become one of our methods.</p>
<p><strong>We can also balance the FP, FN by adjusting DICE and BCE’s weight. It is essential for us to decrease FP since it is the main gap between the state of art model. We retain so many FP in predicting.</strong></p>
<h2 id="Data-augmentation"><a href="#Data-augmentation" class="headerlink" title="Data augmentation"></a>Data augmentation</h2><p><strong>I spent many time on this part because I believe it is the most important part besides the model, also this part may determine which pipeline is better between many good models.</strong></p>
<p>Last week we have discussed a lot about augmentation’s details. This week I rewrite several of them, and learned many different augmentation methods from many sources( mature pipeline, API, challenge winner and papers) I compare their results by rewrite their codes and visualize the results. Some of the codes  I read are hard to understand(like gunpowder) since it contain a whole pipeline’s complex manipulation. </p>
<p><strong>I have applied several of them and implement them in training and testing pipeline.</strong></p>
<p>The codes for final use is: <a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/bin/augmentation.py" target="_blank" rel="noopener">Summer_Intern/augmentation.py at master · james20141606/Summer_Intern · GitHub</a><br>And the implementation and visualization codes:<br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/jupyter/cremi_augmentation_implementation.ipynb" target="_blank" rel="noopener">Summer_Intern/cremi_augmentation_implementation.ipynb at master · james20141606/Summer_Intern · GitHub</a><br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/jupyter/augment_cremi.ipynb" target="_blank" rel="noopener">Summer_Intern/augment_cremi.ipynb at master · james20141606/Summer_Intern · GitHub</a></p>
<h3 id="training"><a href="#training" class="headerlink" title="training"></a>training</h3><p>I do transformation on image and mask at the same time. For simple augmentation it is simple, for elastic transformation, I use random seed to reproduce, and binarize mask data to 0, 1 again. For intensity augmentation  I don’t do any transformation on mask. For defect transformation, there are many to notice, including random seed to reproduce and binarize. </p>
<p>I do many visualization to benchmark every augmentation</p>
<h5 id="train"><a href="#train" class="headerlink" title="train"></a>train</h5><h4 id="simple-augmentation-1"><a href="#simple-augmentation-1" class="headerlink" title="simple augmentation"></a>simple augmentation</h4><p>Do X, Y, Z mirror and transpose, so in total there are 16 methods. Produce a list to generate four 0, 1 random int to decide do or not do these four methods. Do same transformation on image and mask.</p>
<p>Usage:  simpleaug_train_produce()<br><img src="http://i1.fuimg.com/640680/b230e7beb1ffb4fd.png" alt="Markdown"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># produce 16 binary arr</span></span><br><span class="line">binaryarr = np.zeros([<span class="number">16</span>, <span class="number">4</span>]).astype(<span class="string">'int'</span>)</span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">16</span>):</span><br><span class="line">    binaryarr[t] = np.concatenate((np.repeat(<span class="number">0</span>, <span class="number">4</span>-len(bin(t)[<span class="number">2</span>:])), np.array(</span><br><span class="line">        [bin(t)[<span class="number">2</span>:][i] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(bin(t)[<span class="number">2</span>:]))]).astype(<span class="string">'int'</span>)))</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">augmentsimple</span><span class="params">(data, rule)</span>:</span></span><br><span class="line">    <span class="keyword">assert</span> np.size(rule) == <span class="number">4</span> <span class="keyword">and</span> data.ndim == <span class="number">3</span></span><br><span class="line">    <span class="comment"># z reflection.</span></span><br><span class="line">    <span class="keyword">if</span> rule[<span class="number">0</span>]:</span><br><span class="line">        data = data[::<span class="number">-1</span>, :, :]</span><br><span class="line">    <span class="comment"># x reflection.</span></span><br><span class="line">    <span class="keyword">if</span> rule[<span class="number">1</span>]:</span><br><span class="line">        data = data[:, :, ::<span class="number">-1</span>]</span><br><span class="line">    <span class="comment"># y reflection.</span></span><br><span class="line">    <span class="keyword">if</span> rule[<span class="number">2</span>]:</span><br><span class="line">        data = data[:, ::<span class="number">-1</span>, :]</span><br><span class="line">    <span class="comment"># Transpose in xy.</span></span><br><span class="line">    <span class="keyword">if</span> rule[<span class="number">3</span>]:</span><br><span class="line">        data = data.transpose(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">produce_simple_16_sample</span><span class="params">(imgs, imgshape)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    imgs: 24*256*256 -&gt; 16*24*256*256</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="keyword">assert</span> imgs.ndim == <span class="number">3</span></span><br><span class="line">    augmentsimplearr = np.ndarray(</span><br><span class="line">        [<span class="number">16</span>, imgshape[<span class="number">0</span>], imgshape[<span class="number">1</span>], imgshape[<span class="number">2</span>]])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">16</span>):</span><br><span class="line">        augmentsimplearr[i] = augmentsimple(imgs, binaryarr[i])</span><br><span class="line">    <span class="keyword">return</span> augmentsimplearr</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">produce_simple_train_sample</span><span class="params">(imgs, rule)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    imgs: 24*256*256 -&gt; 16*24*256*256</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="keyword">assert</span> imgs.ndim == <span class="number">3</span></span><br><span class="line">    <span class="keyword">return</span> augmentsimple(imgs, rule)</span><br></pre></td></tr></table></figure>
<h4 id="intensity-augmentation"><a href="#intensity-augmentation" class="headerlink" title="intensity augmentation"></a>intensity augmentation</h4><p>Usage: IntensityAugment()</p>
<p>Use <strong>mix</strong> mode for random choose 2D or 3D intensity augmentation. I do not transform mask because there is only pixel shift. </p>
<p><img src="http://i1.fuimg.com/640680/8f09339677f17d82.png" alt="Markdown"></p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IntensityAugment</span>():</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>,  mode=<span class="string">'mix'</span>, skip_ratio=<span class="number">0</span>.<span class="number">3</span>, CONTRAST_FACTOR=<span class="number">0</span>.<span class="number">3</span>, BRIGHTNESS_FACTOR=<span class="number">0</span>.<span class="number">3</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">        Initialize parameters.</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            mode: 2D, 3D, or mix</span></span><br><span class="line"><span class="string">        "</span><span class="string">""</span></span><br><span class="line">        assert mode == <span class="string">'3D'</span> <span class="keyword">or</span> mode == <span class="string">'2D'</span> <span class="keyword">or</span> mode == <span class="string">'mix'</span></span><br><span class="line">        <span class="keyword">self</span>.mode = mode</span><br><span class="line">        <span class="keyword">self</span>.ratio = skip_ratio</span><br><span class="line">        <span class="keyword">self</span>.CONTRAST_FACTOR = CONTRAST_FACTOR</span><br><span class="line">        <span class="keyword">self</span>.BRIGHTNESS_FACTOR = BRIGHTNESS_FACTOR</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">augment</span><span class="params">(<span class="keyword">self</span>, imgs)</span></span><span class="symbol">:</span></span><br><span class="line">        skiprand = np.random.rand()</span><br><span class="line">        <span class="keyword">if</span> skiprand &gt; <span class="keyword">self</span>.<span class="symbol">ratio:</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">self</span>.mode == <span class="string">'mix'</span><span class="symbol">:</span></span><br><span class="line">                threshold = <span class="number">1</span>-(<span class="number">1</span>-<span class="keyword">self</span>.ratio)/<span class="number">2</span></span><br><span class="line">                mode<span class="number">_</span> = <span class="string">'3D'</span> <span class="keyword">if</span> skiprand &gt; threshold <span class="keyword">else</span> <span class="string">'2D'</span> </span><br><span class="line">            <span class="symbol">else:</span></span><br><span class="line">                mode<span class="number">_</span> = <span class="keyword">self</span>.mode</span><br><span class="line">            <span class="keyword">if</span> mode<span class="number">_</span> == <span class="string">'2D'</span><span class="symbol">:</span></span><br><span class="line">                imgs = <span class="keyword">self</span>.augment2D(imgs)</span><br><span class="line">            elif mode<span class="number">_</span> == <span class="string">'3D'</span><span class="symbol">:</span></span><br><span class="line">                imgs = <span class="keyword">self</span>.augment3D(imgs)</span><br><span class="line">            <span class="keyword">return</span> imgs</span><br><span class="line">        <span class="symbol">else:</span></span><br><span class="line">            <span class="keyword">return</span> imgs</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">augment2D</span><span class="params">(<span class="keyword">self</span>, imgs)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">for</span> z <span class="keyword">in</span> range(imgs.shape[-<span class="number">3</span>])<span class="symbol">:</span></span><br><span class="line">            img = imgs[z, <span class="symbol">:</span>, <span class="symbol">:</span>]</span><br><span class="line">            img *= <span class="number">1</span> + (np.random.rand() - <span class="number">0</span>.<span class="number">5</span>)*<span class="keyword">self</span>.CONTRAST_FACTOR</span><br><span class="line">            img += (np.random.rand() - <span class="number">0</span>.<span class="number">5</span>)*<span class="keyword">self</span>.BRIGHTNESS_FACTOR</span><br><span class="line">            img = np.clip(img, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">            img **= <span class="number">2.0</span>**(np.random.rand()*<span class="number">2</span> - <span class="number">1</span>)</span><br><span class="line">            imgs[z, <span class="symbol">:</span>, <span class="symbol">:</span>] = img</span><br><span class="line">        <span class="keyword">return</span> imgs</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">augment3D</span><span class="params">(<span class="keyword">self</span>, imgs)</span></span><span class="symbol">:</span></span><br><span class="line">        imgs *= <span class="number">1</span> + (np.random.rand() - <span class="number">0</span>.<span class="number">5</span>)*<span class="keyword">self</span>.CONTRAST_FACTOR</span><br><span class="line">        imgs += (np.random.rand() - <span class="number">0</span>.<span class="number">5</span>)*<span class="keyword">self</span>.BRIGHTNESS_FACTOR</span><br><span class="line">        imgs = np.clip(imgs, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        imgs **= <span class="number">2.0</span>**(np.random.rand()*<span class="number">2</span> - <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> imgs</span><br></pre></td></tr></table></figure>
<h4 id="elastic-augmentation"><a href="#elastic-augmentation" class="headerlink" title="elastic augmentation"></a>elastic augmentation</h4><p>Usage: apply_elastic_transform(img, mask)<br>I compare gunpowder and this <a href="https://www.kaggle.com/bguberfain/elastic-transform-for-data-augmentation" target="_blank" rel="noopener">Elastic Transform for Data Augmentation | Kaggle</a> one, after comparison, it seems gunpowder version elastic has more functions, if we do not use rotate, it is fine.<br>The output range of create_transformation is 0-width, we can normalize the results. And I use random seed to reproduce on images and masks</p>
<p><img src="http://i1.fuimg.com/640680/b57e8e884c754591.png" alt="Markdown"></p>
<figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br></pre></td><td class="code"><pre><span class="line">def create_identity_transformation(shape, <span class="built_in">subsample</span>=<span class="number">1</span>):</span><br><span class="line">    dims = len(shape)</span><br><span class="line">    subsample_shape = tuple(<span class="built_in">max</span>(<span class="number">1</span>, int(s/<span class="built_in">subsample</span>)) <span class="keyword">for</span> s <span class="keyword">in</span> shape)</span><br><span class="line">    step_width = tuple(<span class="built_in">float</span>(shape[d]-<span class="number">1</span>)/(subsample_shape[d]-<span class="number">1</span>)</span><br><span class="line">                       <span class="keyword">if</span> subsample_shape[d] &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">1</span> <span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">range</span>(dims))</span><br><span class="line">    axis_ranges = (</span><br><span class="line">        <span class="built_in">np</span>.arange(subsample_shape[d], dtype=<span class="built_in">np</span>.float32)*step_width[d]</span><br><span class="line">        <span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">range</span>(dims)</span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">return</span> <span class="built_in">np</span>.<span class="built_in">array</span>(<span class="built_in">np</span>.meshgrid(*axis_ranges, indexing='ij'), dtype=<span class="built_in">np</span>.float32)</span><br><span class="line"></span><br><span class="line">def upscale_transformation(transformation, output_shape, interpolate_order=<span class="number">1</span>):</span><br><span class="line">    input_shape = transformation.shape[<span class="number">1</span>:]</span><br><span class="line">    dims = len(output_shape)</span><br><span class="line">    <span class="built_in">scale</span> = tuple(<span class="built_in">float</span>(s)/c <span class="keyword">for</span> s, c <span class="keyword">in</span> zip(output_shape, input_shape))</span><br><span class="line">    scaled = <span class="built_in">np</span>.zeros((dims,)+output_shape, dtype=<span class="built_in">np</span>.float32)</span><br><span class="line">    <span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">range</span>(dims):</span><br><span class="line">        zoom(transformation[d], zoom=<span class="built_in">scale</span>,</span><br><span class="line">             output=scaled[d], order=interpolate_order)</span><br><span class="line">    <span class="built_in">return</span> scaled</span><br><span class="line"></span><br><span class="line">def create_elastic_transformation(shape, control_point_spacing=<span class="number">100</span>, jitter_sigma=<span class="number">10.0</span>, <span class="built_in">subsample</span>=<span class="number">1</span>):</span><br><span class="line">    dims = len(shape)</span><br><span class="line">    subsample_shape = tuple(<span class="built_in">max</span>(<span class="number">1</span>, int(s/<span class="built_in">subsample</span>)) <span class="keyword">for</span> s <span class="keyword">in</span> shape)</span><br><span class="line">    try:</span><br><span class="line">        spacing = tuple((d <span class="keyword">for</span> d <span class="keyword">in</span> control_point_spacing))</span><br><span class="line">    except:</span><br><span class="line">        spacing = (control_point_spacing,)*dims</span><br><span class="line">    try:</span><br><span class="line">        sigmas = [s <span class="keyword">for</span> s <span class="keyword">in</span> jitter_sigma]</span><br><span class="line">    except:</span><br><span class="line">        sigmas = [jitter_sigma]*dims</span><br><span class="line">    control_points = tuple(</span><br><span class="line">        <span class="built_in">max</span>(<span class="number">1</span>, int(<span class="built_in">round</span>(<span class="built_in">float</span>(shape[d])/spacing[d])))</span><br><span class="line">        <span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">range</span>(len(shape))</span><br><span class="line">    )</span><br><span class="line">    control_point_offsets = <span class="built_in">np</span>.zeros(</span><br><span class="line">        (dims,) + control_points, dtype=<span class="built_in">np</span>.float32)</span><br><span class="line">    <span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">range</span>(dims):</span><br><span class="line">        <span class="keyword">if</span> sigmas[d] &gt; <span class="number">0</span>:</span><br><span class="line">            control_point_offsets[d] = <span class="built_in">np</span>.<span class="built_in">random</span>.normal(</span><br><span class="line">                <span class="built_in">scale</span>=sigmas[d], size=control_points)</span><br><span class="line">    <span class="built_in">return</span> upscale_transformation(control_point_offsets, subsample_shape, interpolate_order=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def rotate(point, angle):</span><br><span class="line">    res = <span class="built_in">np</span>.<span class="built_in">array</span>(point)</span><br><span class="line">    res[<span class="number">0</span>] = math.<span class="built_in">sin</span>(angle)*point[<span class="number">1</span>] + math.<span class="built_in">cos</span>(angle)*point[<span class="number">0</span>]</span><br><span class="line">    res[<span class="number">1</span>] = -math.<span class="built_in">sin</span>(angle)*point[<span class="number">0</span>] + math.<span class="built_in">cos</span>(angle)*point[<span class="number">1</span>]</span><br><span class="line">    <span class="built_in">return</span> res</span><br><span class="line"></span><br><span class="line">def create_rotation_transformation(shape, angle, <span class="built_in">subsample</span>=<span class="number">1</span>):</span><br><span class="line">    dims = len(shape)</span><br><span class="line">    subsample_shape = tuple(<span class="built_in">max</span>(<span class="number">1</span>, int(s/<span class="built_in">subsample</span>)) <span class="keyword">for</span> s <span class="keyword">in</span> shape)</span><br><span class="line">    control_points = (<span class="number">2</span>,)*dims</span><br><span class="line">    control_point_scaling_factor = tuple(<span class="built_in">float</span>(s-<span class="number">1</span>) <span class="keyword">for</span> s <span class="keyword">in</span> shape)</span><br><span class="line">    <span class="built_in">center</span> = <span class="built_in">np</span>.<span class="built_in">array</span>([<span class="number">0.5</span>*(d-<span class="number">1</span>) <span class="keyword">for</span> d <span class="keyword">in</span> shape])</span><br><span class="line">    control_point_offsets = <span class="built_in">np</span>.zeros(</span><br><span class="line">        (dims,) + control_points, dtype=<span class="built_in">np</span>.float32)</span><br><span class="line">    <span class="keyword">for</span> control_point <span class="keyword">in</span> <span class="built_in">np</span>.ndindex(control_points):</span><br><span class="line"></span><br><span class="line">        point = <span class="built_in">np</span>.<span class="built_in">array</span>(control_point)*control_point_scaling_factor</span><br><span class="line">        center_offset = <span class="built_in">np</span>.<span class="built_in">array</span>(</span><br><span class="line">            [p-c <span class="keyword">for</span> c, p <span class="keyword">in</span> zip(<span class="built_in">center</span>, point)], dtype=<span class="built_in">np</span>.float32)</span><br><span class="line">        rotated_offset = <span class="built_in">np</span>.<span class="built_in">array</span>(center_offset)</span><br><span class="line">        rotated_offset[-<span class="number">2</span>:] = rotate(center_offset[-<span class="number">2</span>:], angle)</span><br><span class="line">        displacement = rotated_offset - center_offset</span><br><span class="line">        control_point_offsets[(slice(None),) + control_point] += displacement</span><br><span class="line"></span><br><span class="line">    <span class="built_in">return</span> upscale_transformation(control_point_offsets, subsample_shape)</span><br><span class="line"></span><br><span class="line">def random_offset(max_misalign):</span><br><span class="line">    <span class="built_in">return</span> Coordinate((<span class="number">0</span>,) + tuple(max_misalign - <span class="built_in">random</span>.randint(<span class="number">0</span>, <span class="number">2</span>*int(max_misalign)) <span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">def misalign(transformation, prob_slip, prob_shift, max_misalign):</span><br><span class="line">    num_sections = transformation[<span class="number">0</span>].shape[<span class="number">0</span>]</span><br><span class="line">    <span class="built_in">print</span> (num_sections)</span><br><span class="line">    shifts = [Coordinate((<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>))]*num_sections</span><br><span class="line">    <span class="keyword">for</span> z <span class="keyword">in</span> <span class="built_in">range</span>(num_sections):</span><br><span class="line">        r = <span class="built_in">random</span>.<span class="built_in">random</span>()</span><br><span class="line">        <span class="keyword">if</span> r &lt;= prob_slip:</span><br><span class="line">            shifts[z] = random_offset(max_misalign)</span><br><span class="line">        elif r &lt;= prob_slip + prob_shift:</span><br><span class="line">            offset = random_offset(max_misalign)</span><br><span class="line">            <span class="keyword">for</span> zp <span class="keyword">in</span> <span class="built_in">range</span>(z, num_sections):</span><br><span class="line">                shifts[zp] += offset</span><br><span class="line">                #<span class="built_in">print</span> ('shiftzp '+str(shifts[zp]))</span><br><span class="line">    <span class="keyword">for</span> z <span class="keyword">in</span> <span class="built_in">range</span>(num_sections):</span><br><span class="line">        transformation[<span class="number">1</span>][z, :, :] += shifts[z][<span class="number">1</span>]</span><br><span class="line">        transformation[<span class="number">2</span>][z, :, :] += shifts[z][<span class="number">2</span>]</span><br><span class="line">    <span class="built_in">return</span> transformation</span><br><span class="line">class ElasticAugment():</span><br><span class="line">    def __init__(</span><br><span class="line">            self,</span><br><span class="line">            control_point_spacing,</span><br><span class="line">            jitter_sigma,</span><br><span class="line">            rotation_interval,</span><br><span class="line">            prob_slip=<span class="number">0</span>,</span><br><span class="line">            prob_shift=<span class="number">0</span>,</span><br><span class="line">            max_misalign=<span class="number">0</span>,</span><br><span class="line">            <span class="built_in">subsample</span>=<span class="number">1</span>):</span><br><span class="line">        self.control_point_spacing = control_point_spacing</span><br><span class="line">        self.jitter_sigma = jitter_sigma</span><br><span class="line">        self.rotation_start = rotation_interval[<span class="number">0</span>]</span><br><span class="line">        self.rotation_max_amount = rotation_interval[<span class="number">1</span>] - rotation_interval[<span class="number">0</span>]</span><br><span class="line">        self.prob_slip = prob_slip</span><br><span class="line">        self.prob_shift = prob_shift</span><br><span class="line">        self.max_misalign = max_misalign</span><br><span class="line">        self.<span class="built_in">subsample</span> = <span class="built_in">subsample</span></span><br><span class="line">    def create_transformation(self, target_shape):</span><br><span class="line">        transformation = create_identity_transformation(</span><br><span class="line">            target_shape,</span><br><span class="line">            <span class="built_in">subsample</span>=self.<span class="built_in">subsample</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">sum</span>(self.jitter_sigma) &gt; <span class="number">0</span>:</span><br><span class="line">            transformation += create_elastic_transformation(</span><br><span class="line">                target_shape,</span><br><span class="line">                self.control_point_spacing,</span><br><span class="line">                self.jitter_sigma,</span><br><span class="line">                <span class="built_in">subsample</span>=self.<span class="built_in">subsample</span>)</span><br><span class="line">        rotation = <span class="built_in">random</span>.<span class="built_in">random</span>()*self.rotation_max_amount + self.rotation_start</span><br><span class="line">        <span class="keyword">if</span> rotation != <span class="number">0</span>:</span><br><span class="line">            transformation += create_rotation_transformation(</span><br><span class="line">                target_shape,</span><br><span class="line">                rotation,</span><br><span class="line">                <span class="built_in">subsample</span>=self.<span class="built_in">subsample</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.<span class="built_in">subsample</span> &gt; <span class="number">1</span>:</span><br><span class="line">            transformation = upscale_transformation(</span><br><span class="line">                transformation,</span><br><span class="line">                target_shape)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.prob_slip + self.prob_shift &gt; <span class="number">0</span>:</span><br><span class="line">            misalign(transformation, self.prob_slip,</span><br><span class="line">                     self.prob_shift, self.max_misalign)</span><br><span class="line">        <span class="built_in">return</span> transformation</span><br><span class="line">def apply_transformation(<span class="built_in">image</span>, transformation, interpolate=True, outside_value=<span class="number">0</span>, output=None):</span><br><span class="line"></span><br><span class="line">    # <span class="built_in">print</span>(<span class="string">"Applying transformation..."</span>)</span><br><span class="line">    order = <span class="number">1</span> <span class="keyword">if</span> interpolate == True <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    output = <span class="built_in">image</span>.dtype <span class="keyword">if</span> output <span class="built_in">is</span> None <span class="keyword">else</span> output</span><br><span class="line">    <span class="built_in">return</span> map_coordinates(<span class="built_in">image</span>, transformation, output=output, order=order, mode='<span class="built_in">constant</span>', cval=outside_value)</span><br><span class="line"></span><br><span class="line">def apply_elastic_transform(img, mask):</span><br><span class="line">    assert img.shape[<span class="number">1</span>] == img.shape[<span class="number">2</span>]</span><br><span class="line">    img *= img.shape[<span class="number">1</span>]</span><br><span class="line">    <span class="built_in">transform</span> = ElasticAugment([<span class="number">4</span>, <span class="number">40</span>, <span class="number">40</span>], [<span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>], [<span class="number">0</span>, <span class="number">0</span>], prob_slip=<span class="number">0.05</span>,</span><br><span class="line">                               prob_shift=<span class="number">0.05</span>, max_misalign=<span class="number">25</span>).create_transformation([img.shape[<span class="number">0</span>], img.shape[<span class="number">1</span>], img.shape[<span class="number">2</span>]])</span><br><span class="line">    img_transform = apply_transformation(img,</span><br><span class="line">                                         <span class="built_in">transform</span>,</span><br><span class="line">                                         interpolate=False,</span><br><span class="line">                                         outside_value=img.dtype.type(-<span class="number">1</span>),</span><br><span class="line">                                         output=<span class="built_in">np</span>.zeros(img.shape, dtype=<span class="built_in">np</span>.float32))</span><br><span class="line">    seg_transform = apply_transformation(mask,</span><br><span class="line">                                         <span class="built_in">transform</span>,</span><br><span class="line">                                         interpolate=False,</span><br><span class="line">                                         outside_value=mask.dtype.type(-<span class="number">1</span>),</span><br><span class="line">                                         output=<span class="built_in">np</span>.zeros(mask.shape, dtype=<span class="built_in">np</span>.float32))(<span class="built_in">np</span>.<span class="built_in">unique</span>(seg_transform.ravel()),<span class="built_in">np</span>.<span class="built_in">unique</span>(<span class="built_in">transform</span>.ravel()))</span><br><span class="line">    seg_transform[seg_transform &gt; <span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">    seg_transform[seg_transform != <span class="number">1</span>] = <span class="number">0</span></span><br><span class="line">    <span class="built_in">return</span> img_transform/img_transform.shape[<span class="number">1</span>], seg_transform</span><br></pre></td></tr></table></figure>
<h4 id="defect-augmentation"><a href="#defect-augmentation" class="headerlink" title="defect augmentation"></a>defect augmentation</h4><p>Usage: transformedimgs, transformedmasks = apply_deform(testdatraw/256.,testdatseg,0,20,0.08)</p>
<p><img src="http://i1.fuimg.com/640680/3dfea030bf017168.png" alt="Markdown"></p>
<p>I use gunpowder’s defect, the block region used to be zero, but I change it to zero for better batch normalization results. I use random seed to reproduce images and masks. The block size and missing section’s ratio can change. </p>
<figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">def prepare_deform_slice(slice_shape, deformation_strength, <span class="built_in">iterations</span>, randomseed):</span><br><span class="line">    <span class="built_in">np</span>.<span class="built_in">random</span>.seed(randomseed)</span><br><span class="line">    grow_by = <span class="number">2</span> * deformation_strength</span><br><span class="line">    shape = (slice_shape[<span class="number">0</span>] + grow_by, slice_shape[<span class="number">1</span>] + grow_by)</span><br><span class="line">    fixed_x = <span class="built_in">np</span>.<span class="built_in">random</span>.<span class="built_in">random</span>() &lt; .<span class="number">5</span></span><br><span class="line">    <span class="keyword">if</span> fixed_x:</span><br><span class="line">        x0, y0 = <span class="number">0</span>, <span class="built_in">np</span>.<span class="built_in">random</span>.randint(<span class="number">1</span>, shape[<span class="number">1</span>] - <span class="number">2</span>)</span><br><span class="line">        x1, y1 = shape[<span class="number">0</span>] - <span class="number">1</span>, <span class="built_in">np</span>.<span class="built_in">random</span>.randint(<span class="number">1</span>, shape[<span class="number">1</span>] - <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        x0, y0 = <span class="built_in">np</span>.<span class="built_in">random</span>.randint(<span class="number">1</span>, shape[<span class="number">0</span>] - <span class="number">2</span>), <span class="number">0</span></span><br><span class="line">        x1, y1 = <span class="built_in">np</span>.<span class="built_in">random</span>.randint(<span class="number">1</span>, shape[<span class="number">0</span>] - <span class="number">2</span>), shape[<span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">    line_mask = <span class="built_in">np</span>.zeros(shape, dtype='bool')</span><br><span class="line">    rr, cc = line(x0, y0, x1, y1)</span><br><span class="line">    line_mask[rr, cc] = <span class="number">1</span></span><br><span class="line">    line_vector = <span class="built_in">np</span>.<span class="built_in">array</span>([x1 - x0, y1 - y0], dtype='float32')</span><br><span class="line">    line_vector /= <span class="built_in">np</span>.linalg.norm(line_vector)</span><br><span class="line">    normal_vector = <span class="built_in">np</span>.zeros_like(line_vector)</span><br><span class="line">    normal_vector[<span class="number">0</span>] = - line_vector[<span class="number">1</span>]</span><br><span class="line">    normal_vector[<span class="number">1</span>] = line_vector[<span class="number">0</span>]</span><br><span class="line">    x, y = <span class="built_in">np</span>.meshgrid(<span class="built_in">np</span>.arange(shape[<span class="number">1</span>]), <span class="built_in">np</span>.arange(shape[<span class="number">0</span>]))</span><br><span class="line">    flow_x, flow_y = <span class="built_in">np</span>.zeros(shape), <span class="built_in">np</span>.zeros(shape)</span><br><span class="line">    <span class="built_in">components</span>, n_components = <span class="built_in">label</span>(<span class="built_in">np</span>.logical_not(line_mask).<span class="built_in">view</span>('uint8'))</span><br><span class="line">    assert n_components == <span class="number">2</span>, <span class="string">"%i"</span> <span class="symbol">%</span> n_components</span><br><span class="line">    neg_val = <span class="built_in">components</span>[<span class="number">0</span>, <span class="number">0</span>] <span class="keyword">if</span> fixed_x <span class="keyword">else</span> <span class="built_in">components</span>[-<span class="number">1</span>, -<span class="number">1</span>]</span><br><span class="line">    pos_val = <span class="built_in">components</span>[-<span class="number">1</span>, -<span class="number">1</span>] <span class="keyword">if</span> fixed_x <span class="keyword">else</span> <span class="built_in">components</span>[<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">    flow_x[<span class="built_in">components</span> == pos_val] = deformation_strength * normal_vector[<span class="number">1</span>]</span><br><span class="line">    flow_y[<span class="built_in">components</span> == pos_val] = deformation_strength * normal_vector[<span class="number">0</span>]</span><br><span class="line">    flow_x[<span class="built_in">components</span> == neg_val] = - deformation_strength * normal_vector[<span class="number">1</span>]</span><br><span class="line">    flow_y[<span class="built_in">components</span> == neg_val] = - deformation_strength * normal_vector[<span class="number">0</span>]</span><br><span class="line">    flow_x, flow_y = (x + flow_x).reshape(-<span class="number">1</span>, <span class="number">1</span>), (y + flow_y).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    line_mask = binary_dilation(line_mask, <span class="built_in">iterations</span>=<span class="built_in">iterations</span>)  # default=<span class="number">10</span></span><br><span class="line">    <span class="built_in">return</span> flow_x, flow_y, line_mask</span><br><span class="line"></span><br><span class="line">def deform_2d(image2d, deformation_strength, <span class="built_in">iterations</span>, randomseed):</span><br><span class="line">    flow_x, flow_y, line_mask = prepare_deform_slice(</span><br><span class="line">        image2d.shape, deformation_strength, <span class="built_in">iterations</span>, randomseed)</span><br><span class="line">    section = image2d.squeeze()</span><br><span class="line">    <span class="built_in">mean</span> = section.<span class="built_in">mean</span>()</span><br><span class="line">    shape = section.shape</span><br><span class="line">    #interpolation=<span class="number">3</span></span><br><span class="line">    section = map_coordinates(section, (flow_y, flow_x), mode='<span class="built_in">constant</span>', order=<span class="number">3</span>).reshape(int(flow_x.shape[<span class="number">0</span>]**<span class="number">0.5</span>), int(flow_x.shape[<span class="number">0</span>]**<span class="number">0.5</span>))</span><br><span class="line">    section = <span class="built_in">np</span>.clip(section, <span class="number">0</span>., <span class="number">1</span>.)</span><br><span class="line">    section[line_mask] = <span class="built_in">mean</span></span><br><span class="line">    <span class="built_in">return</span> section</span><br><span class="line"></span><br><span class="line">def apply_deform(imgs, masks, deformation_strength=<span class="number">0</span>, <span class="built_in">iterations</span>=<span class="number">20</span>, deform_ratio=<span class="number">0.08</span>):</span><br><span class="line">    transformedimgs, transformedmasks = &#123;&#125;, &#123;&#125;</span><br><span class="line">    sectionsnum = imgs.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(sectionsnum):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">random</span>.<span class="built_in">random</span>() &lt;= deform_ratio:</span><br><span class="line">            randomseed = <span class="built_in">np</span>.<span class="built_in">random</span>.randint(<span class="number">1000000</span>)</span><br><span class="line">            transformedimgs[i] = deform_2d(</span><br><span class="line">                imgs[i], deformation_strength, <span class="built_in">iterations</span>, randomseed)</span><br><span class="line">            transformedmasks[i] = deform_2d(</span><br><span class="line">                masks[i], deformation_strength, <span class="built_in">iterations</span>, randomseed)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            transformedimgs[i] = imgs[i]</span><br><span class="line">            transformedmasks[i] = masks[i]</span><br><span class="line">    <span class="built_in">return</span> transformedimgs, transformedmasks</span><br></pre></td></tr></table></figure>
<h3 id="test"><a href="#test" class="headerlink" title="test"></a>test</h3><p>For each sample in test, I will produce 16 transformed images and reverse the predicted masks later.</p>
<p>Usage: simpleaug_test_produce()</p>
<p>Usage: simpleaug_test_reverse()</p>
<p>In test, it is common to only use 16 kinds <strong>simple augmentation</strong></p>
<p>For X Y Z axis mirro and xy transpose, in all $2^4 = 16$ images produced.</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">simpleaug_test_produce</span>():</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, model_io_size=[<span class="number">24</span>, <span class="number">256</span>, <span class="number">256</span>])</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.model_io_size = model_io_size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(<span class="keyword">self</span>, imgs)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">return</span> produce_simple_16_sample(imgs, <span class="keyword">self</span>.model_io_size)</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">simpleaug_train_produce</span>():</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, model_io_size=[<span class="number">24</span>, <span class="number">256</span>, <span class="number">256</span>])</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.rule = np.random.randint(<span class="number">2</span>, size=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(<span class="keyword">self</span>, imgs, mask)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="comment">#print (self.rule)</span></span><br><span class="line">        imgs_aug = produce_simple_train_sample(imgs, <span class="keyword">self</span>.rule)</span><br><span class="line">        mask_aug = produce_simple_train_sample(mask, <span class="keyword">self</span>.rule)</span><br><span class="line">        <span class="keyword">return</span> imgs_aug, mask_aug</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">simpleaug_test_reverse</span>():</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, model_io_size=[<span class="number">24</span>, <span class="number">256</span>, <span class="number">256</span>])</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.model_io_size = model_io_size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">augmentsimplereverse</span><span class="params">(<span class="keyword">self</span>,data, rule)</span></span><span class="symbol">:</span></span><br><span class="line">        assert np.size(rule) == <span class="number">4</span> <span class="keyword">and</span> data.ndim == <span class="number">3</span></span><br><span class="line">        <span class="comment"># z reflection.</span></span><br><span class="line">        <span class="keyword">if</span> rule[<span class="number">3</span>]<span class="symbol">:</span></span><br><span class="line">            data = data.transpose(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> rule[<span class="number">2</span>]<span class="symbol">:</span></span><br><span class="line">            data = data[<span class="symbol">:</span>, <span class="symbol">:</span><span class="symbol">:-</span><span class="number">1</span>, <span class="symbol">:</span>]</span><br><span class="line">        <span class="keyword">if</span> rule[<span class="number">1</span>]<span class="symbol">:</span></span><br><span class="line">            data = data[<span class="symbol">:</span>, <span class="symbol">:</span>, <span class="symbol">:</span><span class="symbol">:-</span><span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> rule[<span class="number">0</span>]<span class="symbol">:</span></span><br><span class="line">            data = data[<span class="symbol">:</span><span class="symbol">:-</span><span class="number">1</span>, <span class="symbol">:</span>, <span class="symbol">:</span>]</span><br><span class="line">        <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reverse_and_mean</span><span class="params">(<span class="keyword">self</span>,imgs, imgshape)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="string">''</span><span class="string">'</span></span><br><span class="line"><span class="string">        imgs: 16*24*256*256 -&gt;24*256*256</span></span><br><span class="line"><span class="string">        '</span><span class="string">''</span></span><br><span class="line">        assert imgs.ndim == <span class="number">4</span></span><br><span class="line">        reversedsimplearr = np.ndarray(</span><br><span class="line">            [<span class="number">16</span>, imgshape[<span class="number">0</span>], imgshape[<span class="number">1</span>], imgshape[<span class="number">2</span>]])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">16</span>)<span class="symbol">:</span></span><br><span class="line">            reversedsimplearr[i] = <span class="keyword">self</span>.augmentsimplereverse(imgs[i], binaryarr[i])</span><br><span class="line">        <span class="keyword">return</span> np.mean(reversedsimplearr, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(<span class="keyword">self</span>, imgs)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">self</span>.reverse_and_mean(imgs, <span class="keyword">self</span>.model_io_size)</span><br></pre></td></tr></table></figure>
<h3 id="further-useful-augmentation"><a href="#further-useful-augmentation" class="headerlink" title="further useful augmentation"></a>further useful augmentation</h3><p>I have found many other augmentations in many sources. Since our main aim now is to get a better result in a short time. I will see if the augmentation strategy is enough. If not, I will implement them later. If the augmentation is good enough, we can do more on task 3 later. Since the model is really hard to train and see the results(may take a week for the feedback), time is really precious, and we can’t test one method at one time.</p>
<p>I have tried some here <a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/jupyter/further_aug_imgaug.ipynb" target="_blank" rel="noopener">Summer_Intern/further_aug_imgaug.ipynb at master · james20141606/Summer_Intern · GitHub</a>, but I will decide what to do first next week.</p>
<ul>
<li>2018 annual datascience bowl top1: segment cells<br><a href="https://www.leiphone.com/news/201804/qfus8zALhZLoA8Ai.html" target="_blank" rel="noopener">https://www.leiphone.com/news/201804/qfus8zALhZLoA8Ai.html</a><br>There are many data augmentation methods:<br><a href="https://github.com/selimsef/dsb2018_topcoders/blob/7a87c07e1fb8e090186a3914a1443469f5107962/albu/src/augmentations/transforms.py" target="_blank" rel="noopener">https://github.com/selimsef/dsb2018_topcoders/blob/7a87c07e1fb8e090186a3914a1443469f5107962/albu/src/augmentations/transforms.py</a><br>It seems clear and they used an augmentation API imgaug<br><a href="http://imgaug.readthedocs.io/en/latest/" target="_blank" rel="noopener">imgaug</a><br>Apart from gunpowder’s method, there are a lot to use!</li>
<li>random zoom, rotate, flip</li>
<li>contrast and brightness</li>
<li>heavy geometric transform:  Elastic Transform, Perspective Transform, Piecewise Affine transforms, Pincushion Distortion</li>
<li>contrast limited adaptive histogram equalization (CLAHE) ，Sharpen，Emboss</li>
<li>Gaussian noise</li>
<li>Blur、Median Blur、Motion Blur</li>
<li>HSV</li>
<li>rearrange channel</li>
<li>repeat of cell nuclear</li>
</ul>
<h2 id="future-work"><a href="#future-work" class="headerlink" title="future work"></a>future work</h2><h3 id="compare-with-other-work-and-thoughs"><a href="#compare-with-other-work-and-thoughs" class="headerlink" title="compare with other work and thoughs"></a>compare with other work and thoughs</h3><ul>
<li>For randomly chosen sample, we use pixel ratio to determine if one sample is used to train, Funke use probability,  we can think which is better.</li>
<li>Funke use regression whereas  we use binary classification, it is simple to change to regression, but we should compare our loss function and strategy at first. For example, Funke’s STED loss may not be good.</li>
<li>Funke use auxiliary loss for better prune, but we have visualize the result and find the proposed synapse matchh the membrane well, so it may not be necessary. </li>
</ul>
<h3 id="future-plan"><a href="#future-plan" class="headerlink" title="future plan"></a>future plan</h3><p>As mentioned above, I believe there are more to implement. The state-of-art model and pipeline looks really good, so I think I should use more strategy to improve our results.</p>
<ul>
<li>read and consider V-net’s structure. V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation<br><a href="http://mattmacy.io/vnet.pytorch/" target="_blank" rel="noopener">vnet.pytorch</a><br><a href="https://github.com/mattmacy/vnet.pytorch" target="_blank" rel="noopener">GitHub - mattmacy/vnet.pytorch: A PyTorch implementation for V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation</a><br><a href="https://github.com/mattmacy/torchbiomed" target="_blank" rel="noopener">GitHub - mattmacy/torchbiomed: Datasets, Transforms and Utilities specific to Biomedical Imaging</a></li>
<li>if submitted result has a big difference with Funke’s, I may try to reproduce their work.</li>
<li>read task 3 complete codes apart from  <a href="https://github.com/paragt/EMSynConn" target="_blank" rel="noopener">GitHub - paragt/EMSynConn: One algorithm to detect synaptic location AND connectivity, both dyadic and polyadic, in Electron Microscopy volume.</a></li>
<li>how to fine tune, apart from learning rate adjustment, we should consider some prune work. For example, the paper <strong>Stacked U-Nets with Multi-Output for Road Extraction</strong>:<blockquote>
<p>postprocessing: Various post-processing techniques for road extraction have been proposed in the literature, e.g., centerline extraction using structured SVM or Markov random ﬁeld, handling noisy data using a special CNN, recovering lines by sampling junction-points, and bridging road gaps by heuristic search. Here we develope a novel post processing technique by linking broken roads through shortest path search with decreasing conﬁdence thresholds. More speciﬁcally, we ﬁrst convert the raster road prediction image to vector format so we can bridge gaps and trim spurious roads, then we render a raster image from road vectors and merge it with the original prediction because the challenge needs raster images for IoU calculation.</p>
</blockquote>
</li>
<li>examine results carefully to understand the difference between FP and TP, gain biological intuition from it for better model design. For example the  density of membrane and vesicle</li>
</ul>
<hr>
<h1 id="Week-4"><a href="#Week-4" class="headerlink" title="Week 4"></a>Week 4</h1><p>This week I mainly focus on synaptic partner prediction and NMJ pipeline, and wait for our current models’ result on CREMI synapse prediction challenge.</p>
<h2 id="Loss-adjustment"><a href="#Loss-adjustment" class="headerlink" title="Loss adjustment"></a>Loss adjustment</h2><p>Last week we add DICE loss and this week we change BCE loss to Focal loss. It is adaptive to better consider weights.</p>
<p>P: predict result, GT: ground truth, N: batch size</p>
<script type="math/tex; mode=display">L = 1 - \frac{2 \times \sum_{i=1}^N  |P_i \cap GT_i  | }{\sum_{i=1}^N  (P_i + GT_i)} + \sum_{i=1}^N FocalLoss(P_i,  GT_i)</script><p><img src="http://i4.fuimg.com/640680/52858efa5d322afa.png" alt="Markdown"></p>
<script type="math/tex; mode=display">FocalLoss(pt) = -{(1 - p_t)}^\gamma log(p_t)</script><p><img src="http://i4.fuimg.com/640680/58f54732f92776ef.png" alt="Markdown"></p>
<h2 id="Augmentation-improvement"><a href="#Augmentation-improvement" class="headerlink" title="Augmentation improvement"></a>Augmentation improvement</h2><p>This week I add and improve two augmentation methods: deform and elastic augmetation.<br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/jupyter/cremi_augmentation_implementation.ipynb" target="_blank" rel="noopener">Summer_Intern/cremi_augmentation_implementation.ipynb at master · james20141606/Summer_Intern · GitHub</a></p>
<h3 id="deformation-augmentation"><a href="#deformation-augmentation" class="headerlink" title="deformation augmentation"></a>deformation augmentation</h3><p>Remove random seeds, do not add deformation on masks.<br>Write the function to avoid deformation on adjacent sections. We wish this can force the network pay attention to 3D characteristics of the image.</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">def prepare_deform_slice(slice_shape,deformation_strength,iterations):</span><br><span class="line">    <span class="comment"># grow slice shape by 2 x deformation strength</span></span><br><span class="line">    <span class="attr">grow_by</span> = <span class="number">2</span> * deformation_strength</span><br><span class="line">    <span class="comment">#print ('sliceshape: '+str(slice_shape[0])+' growby: '+str(grow_by)+ ' strength: '+str(deformation_strength))</span></span><br><span class="line">    <span class="attr">shape</span> = (slice_shape[<span class="number">0</span>] + grow_by, slice_shape[<span class="number">1</span>] + grow_by)</span><br><span class="line">    <span class="comment"># randomly choose fixed x or fixed y with p = 1/2</span></span><br><span class="line">    <span class="attr">fixed_x</span> = np.random.random() &lt; .<span class="number">5</span></span><br><span class="line">    <span class="keyword">if</span> fixed_x:</span><br><span class="line">        x0, <span class="attr">y0</span> = <span class="number">0</span>, np.random.randint(<span class="number">1</span>, shape[<span class="number">1</span>] - <span class="number">2</span>)</span><br><span class="line">        x1, <span class="attr">y1</span> = shape[<span class="number">0</span>] - <span class="number">1</span>, np.random.randint(<span class="number">1</span>, shape[<span class="number">1</span>] - <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        x0, <span class="attr">y0</span> = np.random.randint(<span class="number">1</span>, shape[<span class="number">0</span>] - <span class="number">2</span>), <span class="number">0</span></span><br><span class="line">        x1, <span class="attr">y1</span> = np.random.randint(<span class="number">1</span>, shape[<span class="number">0</span>] - <span class="number">2</span>), shape[<span class="number">1</span>] - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">## generate the mask of the line that should be blacked out</span></span><br><span class="line">    <span class="comment">#print (shape)</span></span><br><span class="line">    <span class="attr">line_mask</span> = np.zeros(shape, <span class="attr">dtype='bool')</span></span><br><span class="line">    rr, <span class="attr">cc</span> = line(x0, y0, x1, y1)</span><br><span class="line">    line_mask[rr, cc] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># generate vectorfield pointing towards the line to compress the image</span></span><br><span class="line">    <span class="comment"># first we get the unit vector representing the line</span></span><br><span class="line">    <span class="attr">line_vector</span> = np.array([x1 - x0, y1 - y0], <span class="attr">dtype='float32')</span></span><br><span class="line">    line_vector /= np.linalg.norm(line_vector)</span><br><span class="line">    <span class="comment"># next, we generate the normal to the line</span></span><br><span class="line">    <span class="attr">normal_vector</span> = np.zeros_like(line_vector)</span><br><span class="line">    normal_vector[<span class="number">0</span>] = - line_vector[<span class="number">1</span>]</span><br><span class="line">    normal_vector[<span class="number">1</span>] = line_vector[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># make meshgrid</span></span><br><span class="line">    x, <span class="attr">y</span> = np.meshgrid(np.arange(shape[<span class="number">1</span>]), np.arange(shape[<span class="number">0</span>]))</span><br><span class="line">    <span class="comment"># generate the vector field</span></span><br><span class="line">    flow_x, <span class="attr">flow_y</span> = np.zeros(shape), np.zeros(shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># find the 2 components where coordinates are bigger / smaller than the line</span></span><br><span class="line">    <span class="comment"># to apply normal vector in the correct direction</span></span><br><span class="line">    components, <span class="attr">n_components</span> = label(np.logical_not(line_mask).view('uint8'))</span><br><span class="line">    <span class="keyword">assert</span> <span class="attr">n_components</span> == <span class="number">2</span>, <span class="string">"%i"</span> % n_components</span><br><span class="line">    <span class="attr">neg_val</span> = components[<span class="number">0</span>, <span class="number">0</span>] <span class="keyword">if</span> fixed_x <span class="keyword">else</span> components[-<span class="number">1</span>, -<span class="number">1</span>]</span><br><span class="line">    <span class="attr">pos_val</span> = components[-<span class="number">1</span>, -<span class="number">1</span>] <span class="keyword">if</span> fixed_x <span class="keyword">else</span> components[<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    flow_x[<span class="attr">components</span> == pos_val] = deformation_strength * normal_vector[<span class="number">1</span>]</span><br><span class="line">    flow_y[<span class="attr">components</span> == pos_val] = deformation_strength * normal_vector[<span class="number">0</span>]</span><br><span class="line">    flow_x[<span class="attr">components</span> == neg_val] = - deformation_strength * normal_vector[<span class="number">1</span>]</span><br><span class="line">    flow_y[<span class="attr">components</span> == neg_val] = - deformation_strength * normal_vector[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># generate the flow fields</span></span><br><span class="line">    flow_x, <span class="attr">flow_y</span> = (x + flow_x).reshape(-<span class="number">1</span>, <span class="number">1</span>), (y + flow_y).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># dilate the line mask</span></span><br><span class="line">    <span class="attr">line_mask</span> = binary_dilation(line_mask, <span class="attr">iterations=iterations)#default=10</span></span><br><span class="line">    </span><br><span class="line">    return flow_x, flow_y, line_mask</span><br><span class="line">def deform_2d(image2d,deformation_strength,iterations):</span><br><span class="line">    flow_x, flow_y, <span class="attr">line_mask</span> = prepare_deform_slice(image2d.shape,deformation_strength,iterations)</span><br><span class="line">    <span class="attr">section</span> = image2d.squeeze()</span><br><span class="line">    <span class="attr">mean</span> = section.mean()</span><br><span class="line">    <span class="attr">shape</span> = section.shape</span><br><span class="line">    <span class="comment">#interpolation=3</span></span><br><span class="line">    <span class="attr">section</span> = map_coordinates( section, (flow_y, flow_x), <span class="attr">mode='constant',</span> </span><br><span class="line">                                  <span class="attr">order=3).reshape(int(flow_x.shape[0]**0.5),int(flow_x.shape[0]**0.5))</span></span><br><span class="line">    <span class="attr">section</span> = np.clip(section, <span class="number">0</span>., <span class="number">1</span>.)</span><br><span class="line">    section[line_mask] = mean</span><br><span class="line">    return section </span><br><span class="line">def apply_deform(imgs,<span class="attr">deformation_strength=0,iterations=50,deform_ratio=0.25):</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    imgs :3D</span></span><br><span class="line"><span class="string">    ''</span>'</span><br><span class="line">    <span class="attr">transformedimgs=</span> np.copy(imgs)</span><br><span class="line">    <span class="attr">sectionsnum</span> = imgs.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="attr">i</span> =<span class="number">0</span></span><br><span class="line">    while i &lt;sectionsnum:</span><br><span class="line">        <span class="keyword">if</span> random.random() &lt;= deform_ratio:</span><br><span class="line">            transformedimgs[i] = deform_2d(imgs[i],deformation_strength,iterations)</span><br><span class="line">            i +=<span class="number">2</span></span><br><span class="line">        i +=<span class="number">1</span></span><br><span class="line">    return transformedimgs</span><br></pre></td></tr></table></figure>
<p><img src="http://i4.fuimg.com/640680/2be847081da6e223.png" alt="Markdown"></p>
<h3 id="elastic-augmentation-1"><a href="#elastic-augmentation-1" class="headerlink" title="elastic augmentation"></a>elastic augmentation</h3><figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">from scipy.ndimage.interpolation <span class="keyword">import</span> map_coordinates</span><br><span class="line">from scipy.ndimage.filters <span class="keyword">import</span> gaussian_filter</span><br><span class="line"></span><br><span class="line">def elastic_transform(image, alpha, sigma, random_state=<span class="keyword">None</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> random_state is <span class="keyword">None</span>:</span><br><span class="line">        random_state = np.random.RandomState(<span class="keyword">None</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        random_state = np.random.RandomState(random_state)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">shape</span> = image.<span class="built_in">shape</span></span><br><span class="line">    dx = gaussian_filter((random_state.rand(*<span class="built_in">shape</span>) * <span class="number">2</span> - <span class="number">1</span>), sigma) * alpha</span><br><span class="line">    dy = gaussian_filter((random_state.rand(*<span class="built_in">shape</span>) * <span class="number">2</span> - <span class="number">1</span>), sigma) * alpha</span><br><span class="line">    dz = np.zeros_like(dx)</span><br><span class="line"></span><br><span class="line">    x, y, z = np.meshgrid(np.arange(<span class="built_in">shape</span>[<span class="number">1</span>]), np.arange(<span class="built_in">shape</span>[<span class="number">0</span>]), np.arange(<span class="built_in">shape</span>[<span class="number">2</span>]))</span><br><span class="line">    indices = np.<span class="built_in">reshape</span>(y+dy, (-<span class="number">1</span>, <span class="number">1</span>)), np.<span class="built_in">reshape</span>(x+dx, (-<span class="number">1</span>, <span class="number">1</span>)), np.<span class="built_in">reshape</span>(z, (-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> map_coordinates(image, indices, order=<span class="number">1</span>, mode=<span class="string">'reflect'</span>).<span class="built_in">reshape</span>(<span class="built_in">shape</span>)</span><br><span class="line">def apply_elastic(img,mask):</span><br><span class="line">    <span class="built_in">random_seed</span> = np.random.randint(<span class="number">1000000</span>)</span><br><span class="line">    elasticedraw = elastic_transform(img, img.<span class="built_in">shape</span>[<span class="number">1</span>] * <span class="number">2</span>, img.<span class="built_in">shape</span>[<span class="number">1</span>] * <span class="number">0.07</span>, <span class="built_in">random_seed</span>)</span><br><span class="line">    elasticedseg = elastic_transform(mask, img.<span class="built_in">shape</span>[<span class="number">1</span>] * <span class="number">2</span>, img.<span class="built_in">shape</span>[<span class="number">1</span>] * <span class="number">0.07</span>, <span class="built_in">random_seed</span>)</span><br><span class="line">    <span class="keyword">return</span> elasticedraw, elasticedseg</span><br></pre></td></tr></table></figure>
<p>elastic augmentation is important and should be treated very carefully. I use the idea in Best Practices for Convolutional Neural Networks applied to Visual Document Analysis.</p>
<p>The main methods are Gaussian filter and interpolation. There is a version of elastic augmentation using affine transformation, I test it but the effect is hard to control.</p>
<p>So I use Gaussian filter and interpolation for gentle elastic transformation. Then normalize to 0-1, binarize label and make sure the transformation is same in images and masks.</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">apply_elastic</span><span class="params">(img,mask)</span></span></span><br></pre></td></tr></table></figure>
<p><img src="http://i4.fuimg.com/640680/64061355143fac3a.png" alt="Markdown"></p>
<h2 id="task2-reverse-predicting"><a href="#task2-reverse-predicting" class="headerlink" title="task2 reverse predicting"></a>task2 reverse predicting</h2><p>I have use alignment and padding and shift scripts to process the raw data and it should be reversed after prediction. I test the codes to make sure it works.</p>
<p>Codes: <a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/bin/T_align.m" target="_blank" rel="noopener">Summer_Intern/T_align.m at master · james20141606/Summer_Intern · GitHub</a></p>
<hr>
<h1 id="Week-5-amp-6"><a href="#Week-5-amp-6" class="headerlink" title="Week 5 &amp; 6"></a>Week 5 &amp; 6</h1><h2 id="align-location-volume"><a href="#align-location-volume" class="headerlink" title="align location volume"></a>align location volume</h2><p>I align the annotation about pre and post synaptic partners location for later training and analyze three volumes pre and post’s section distance</p>
<p>It seems that the volume C annotation has some apparent outliers, it is impossible that the two partners have such a big distance, so I removed the outlier with distance more than 300.</p>
<p><img src="http://i4.fuimg.com/640680/5271eb263cb9e565.png" alt="Markdown"></p>
<p><img src="http://i4.fuimg.com/640680/a41fb440d8d1c617.png" alt="Markdown"></p>
<p><img src="http://i4.fuimg.com/640680/132ddef47af261fc.png" alt="Markdown"></p>
<p>The final process include two more changes: do not use good slice replace bad slice<br>And remove partners with distance more than 300. Now the three volumes have 217,634,722 synaptic partners.</p>
<h3 id="data-augmentation"><a href="#data-augmentation" class="headerlink" title="data augmentation"></a>data augmentation</h3><p>For elastic transformation, it is weird to use gaussian filter and then warp, but it is good to use warp first and then do gaussian filter.</p>
<ol>
<li>elastic: smoothed random motion field=random vector+gaussian filter</li>
<li>warping: random global affine matrix</li>
</ol>
<p><img src="http://i4.fuimg.com/640680/208732c8803ea2b3.png" alt="Markdown"></p>
<p><img src="http://i4.fuimg.com/640680/206cd5295b80d561.png" alt="Markdown"></p>
<h2 id="loss-function-and-new-design"><a href="#loss-function-and-new-design" class="headerlink" title="loss function and new design"></a>loss function and new design</h2><ul>
<li>Intensity  influence the result severely, besides decreasing contrast and brightness,<br><a href="http://cs231n.stanford.edu/reports/2017/pdfs/300.pdf" target="_blank" rel="noopener">http://cs231n.stanford.edu/reports/2017/pdfs/300.pdf</a></li>
<li>we can also try group normalization and multi GPU batch normalization.<br>32 channel, 8 groups, each 4 channels</li>
<li>distance transform to assign weight for negative class, similar with tanh(D/S)</li>
<li>multi resolution and multi task learning<br><strong>Multi task!</strong> is using multiple loss on different resolution level and add these lossed together. It is a kind of like attention. But the combined losses are not very precise to control different levels.<br>We may also consider MULTI -SCALE DENSE NETWORKS FOR RESOURCE E FFICIENT IMAGE CLASSIFICATION, it can output results on different resolution levels and are better than resnet based models.</li>
</ul>
<h3 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h3><p>DICE loss are hard to convergence.<br>I formulate some equations to change the DICE loss, and also implement some other DICE loss adjustment.</p>
<p><img src="http://i4.fuimg.com/640680/ceea6995778ee50a.png" alt="Markdown"></p>
<p><img src="http://i4.fuimg.com/640680/b793b22de5ed6051.png" alt="Markdown"></p>
<h5 id="generalized-DICE-loss"><a href="#generalized-DICE-loss" class="headerlink" title="generalized DICE loss"></a>generalized DICE loss</h5><p>Change DICE denominator to square. So that the points having different distance from GT have different  derivative.</p>
<p><img src="http://i4.fuimg.com/640680/d196b3bb76ababaa.png" alt="Markdown"></p>
<p>change denomi<img src="http://i4.fuimg.com/640680/cbdbb1c2f4192ada.png" alt="Markdown"></p>
<p><strong>Using this formulation we do not need to assign weights to samples of different classes to establish the right balance between foreground and background voxels,</strong> and we obtain results that we experimentally observed are much better than the ones computed through the same network trained optimising a multinomial logistic loss with sample re-weighting</p>
<p><strong>DICE Loss</strong><br>consider negative？<br><img src="http://i4.fuimg.com/640680/14a4604e6910d2ef.png" alt="Markdown"></p>
<p><strong>sensitivity-specificity</strong><br><img src="http://i4.fuimg.com/640680/45a62036466fb811.png" alt="Markdown"></p>
<p><strong>weighted dice</strong><br><img src="http://i4.fuimg.com/640680/7597c15cb6c70bd5.png" alt="Markdown"></p>
<p><img src="http://i4.fuimg.com/640680/0fefcfc0276481ba.png" alt="Markdown"></p>
<p>still based only on pairwise comparisons of probabilities associated with the same label and don’t take into account <strong>inter-class relationships.</strong></p>
<h2 id="reverse-prediction-and-deal-with-cracks"><a href="#reverse-prediction-and-deal-with-cracks" class="headerlink" title="reverse prediction and deal with cracks"></a>reverse prediction and deal with cracks</h2><p>For CREMI contest, we do several preprocessing, like align the dataset, and deal with two specific sections with cracks( it is very important, because the crack will severely influence the result.)</p>
<p>I will realign the predicted result to the original one and submit the prediction. And I will deal with two sections with cracks separately.</p>
<h4 id="对那两层做crack-align"><a href="#对那两层做crack-align" class="headerlink" title="对那两层做crack align"></a>对那两层做crack align</h4><ul>
<li><p>[ ] 脚本 align_new</p>
</li>
<li><p>detect crack region and split the picture into two regions</p>
</li>
</ul>
<p><img src="http://i4.fuimg.com/640680/b88ca29cc508e738.png" alt="Markdown"></p>
<ul>
<li>align the two parts with neighbor sections. Use warp to align. The crack will look bigger.</li>
</ul>
<p><img src="http://i4.fuimg.com/640680/d898e30f03ec6e90.png" alt="Markdown"></p>
<ul>
<li>do interpolation, using optical flow</li>
</ul>
<p><img src="http://i4.fuimg.com/640680/a077144bab1af22e.png" alt="Markdown"></p>
<p>Reverse the predicted crack section back:</p>
<ul>
<li>delete interpolation region</li>
<li>find connected region and extract them</li>
<li>reverse warp the two parts</li>
<li><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">imwarp(<span class="name">im</span>, affine2d(<span class="name">tmp</span>(:,:,<span class="number">2</span>)),'FillValues',<span class="number">0</span>,'OutputView',imref2d(<span class="name">sz</span>))<span class="comment">;</span></span><br><span class="line">tform = affine2d([<span class="number">2</span> <span class="number">0.33</span> <span class="number">0</span><span class="comment">; 0 1 0; 0 0 1])</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>For reverse warp, we can use invert function<br><a href="https://www.mathworks.com/help/images/ref/affine2d.invert.html" target="_blank" rel="noopener">Invert geometric transformation - MATLAB invert</a></p>
<ul>
<li>add the two parts</li>
<li>get the reversed images and test if it is right.</li>
</ul>
<p><img src="http://i4.fuimg.com/640680/1f07ed5887f5112b.png" alt="Markdown"></p>
<p>it’s good enough to transform synapse prediction result, no synapse will be on the border<br>So we do not need the padding work</p>
<h4 id="for-predicted-data"><a href="#for-predicted-data" class="headerlink" title="for predicted data:"></a>for predicted data:</h4><ul>
<li>[ ] Use <a href="http://140.247.107.75:8889/notebooks/projects/synapse/jupyter/realign_crack.ipynb" target="_blank" rel="noopener">Jupyter Notebook</a> to get connected components from em<br>And apply invert on them to get reversed version</li>
</ul>
<h3 id="8-6-reverse-all-predictions"><a href="#8-6-reverse-all-predictions" class="headerlink" title="8.6 reverse all predictions"></a>8.6 reverse all predictions</h3><p>A+ B+ C+ reverse prediction<br>Test if the algorithm is right!</p>
<h4 id="use-gt-syn-transformed，and-reverse，check-if-it-is-the-same-with-the-original-one"><a href="#use-gt-syn-transformed，and-reverse，check-if-it-is-the-same-with-the-original-one" class="headerlink" title="use gt-syn transformed，and reverse，check if it is the same with the original one"></a>use gt-syn transformed，and reverse，check if it is the same with the original one</h4><ul>
<li>input: gt-syn/syn</li>
<li>output: reverse/syn<br>Check if output=images/volumes/labels/clefts</li>
</ul>
<p><strong>Rewrite the reverse alignment code</strong><br>after a long time, it finally works, with the help of donglai. It seems it is really hard to reverse back to the original align.</p>
<ul>
<li>The forward strategy looks like:<br>Read alignment shift distance, cumsum to get continuous shift, get each section’s shift. Have a very big tmp arr, put the small original arr in it. Get a bigger ROI to have the  medium one</li>
</ul>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">syn_o=<span class="built_in">zeros</span>([<span class="number">1250</span>+sum(ww([<span class="number">1</span>,<span class="number">3</span>])),<span class="number">1250</span>+sum(ww([<span class="number">2</span>,<span class="number">4</span>])),<span class="number">153</span>],<span class="string">'uint16'</span>);</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="number">125</span></span><br><span class="line">	pd = <span class="built_in">round</span>(pp(<span class="built_in">i</span>+<span class="number">14</span>,:)); </span><br><span class="line">	tmp = <span class="built_in">zeros</span>(<span class="number">3075</span>+ph,<span class="number">3075</span>);</span><br><span class="line">	</span><br><span class="line">	tmp(<span class="number">912</span>:<span class="number">911</span>+<span class="number">1250</span>,<span class="number">912</span>:<span class="number">911</span>+<span class="number">1250</span>) = syn(:,:,<span class="built_in">i</span>);</span><br><span class="line">	syn_o(:,:,<span class="built_in">i</span>+<span class="number">14</span>) = tmp((<span class="number">912</span>+pd(<span class="number">1</span>)-ww(<span class="number">1</span>)):(<span class="number">911</span>+pd(<span class="number">1</span>)+<span class="number">1250</span>+ww(<span class="number">3</span>)),...</span><br><span class="line">	            (<span class="number">912</span>+pd(<span class="number">2</span>)-ww(<span class="number">2</span>)):(<span class="number">911</span>+pd(<span class="number">2</span>)+<span class="number">1250</span>+ww(<span class="number">4</span>))); </span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<ul>
<li>The reverse strategy looks like:<br>Read alignment shift distance, cumsum to get continuous shift, get each section’s shift. Have a very big tmp arr, put the predicted region(medium size) in it. Get a small, original ROI to have the  original one<br><strong>through test there is no problem!</strong></li>
</ul>
<h4 id="A-in-15-and-48-layer-from-one-not-zero-do-reverse-crack"><a href="#A-in-15-and-48-layer-from-one-not-zero-do-reverse-crack" class="headerlink" title="A+: in 15 and 48 layer(from one, not zero), do reverse crack!"></a>A+: in 15 and 48 layer(from one, not zero), do reverse crack!</h4><p>It is 14 and 47 section of predicted A+ syn<br>data/prediction/im015_reverse0.png, data/prediction/im048_reverse0.png</p>
<p><img src="http://i4.fuimg.com/640680/24b6323ecbacadcb.png" alt="Markdown"></p>
<hr>
<h1 id="Last-three-weeks"><a href="#Last-three-weeks" class="headerlink" title="Last three weeks"></a>Last three weeks</h1><p>Week 7,8,9 (10)</p>
<h2 id="8-13"><a href="#8-13" class="headerlink" title="8.13"></a>8.13</h2><p>We add squeeze and excitation block to our model. It further improves our performance on CREMI contest. We achieve 2nd place by the end of August. This architecture also works for synapse polarity prediction task.<br><img src="http://i1.fuimg.com/640680/1b36249fa6f56a59.png" alt="Markdown"></p>
<p><img src="http://i1.fuimg.com/640680/3d5fe582cfbd9d77.png" alt="Markdown"></p>
<h4 id="8-29"><a href="#8-29" class="headerlink" title="8.29"></a>8.29</h4><p>Reverse back a new version</p>
<ul>
<li>Get ROI, delete interpolation region</li>
<li>inverse warp</li>
<li>get reverse0<br>-merge</li>
<li>Put back to predicted A+ and reverse A+</li>
<li><code>/n/coxfs01/xupeng/projects/synapse/data/reverse</code></li>
</ul>

      
    </div>
    
    
    

    

    <div>
    
    <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-----The ---- end ----<i class="fa fa-paw"></i>--- Thanks --- for --- Reading----</div>
    
</div>

    
    </div>

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/blog/tags/project/" rel="tag"><i class="fa fa-tag"></i> project</a>
          
            <a href="/blog/tags/neural-science/" rel="tag"><i class="fa fa-tag"></i> neural science</a>
          
            <a href="/blog/tags/summer-intern/" rel="tag"><i class="fa fa-tag"></i> summer intern</a>
          
            <a href="/blog/tags/connectomics/" rel="tag"><i class="fa fa-tag"></i> connectomics</a>
          
            <a href="/blog/tags/computational-neural-science/" rel="tag"><i class="fa fa-tag"></i> computational neural science</a>
          
            <a href="/blog/tags/deep-learning/" rel="tag"><i class="fa fa-tag"></i> deep learning</a>
          
            <a href="/blog/tags/computer-vision/" rel="tag"><i class="fa fa-tag"></i> computer vision</a>
          
            <a href="/blog/tags/Jeff-Lichtman/" rel="tag"><i class="fa fa-tag"></i> Jeff Lichtman</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/blog/2018/07/14/99_summerintern_NMJ/" rel="next" title="NMJ Project">
                <i class="fa fa-chevron-left"></i> NMJ Project
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/blog/2018/07/14/97_summerintern_Synaptic_Partner_and_Cluster_Project/" rel="prev" title="Synaptic Partner and Cluster Project">
                Synaptic Partner and Cluster Project <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC80Njc1My8yMzI1NQ=="></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/blog/images/avatar.png"
                alt="James Chen" />
            
              <p class="site-author-name" itemprop="name">James Chen</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/blog/archives/">
              
                  <span class="site-state-item-count">99</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/blog/categories/index.html">
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/blog/tags/index.html">
                  <span class="site-state-item-count">92</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/blog/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/james20141606" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:xp-chen14@mails.tsinghua.edu.cn" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=d9dbc8&w=a&t=n&d=MGAfMNv-Snrv0Yg1d2t2EH3ATBUCJtdgbna_qHvb4AI&co=302dad'></script>

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Codes"><span class="nav-number">1.</span> <span class="nav-text">Codes</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#weekly-report"><span class="nav-number">2.</span> <span class="nav-text">weekly report</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#First"><span class="nav-number">2.1.</span> <span class="nav-text">First</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Second"><span class="nav-number">2.2.</span> <span class="nav-text">Second</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Third"><span class="nav-number">2.3.</span> <span class="nav-text">Third</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Fourth"><span class="nav-number">2.4.</span> <span class="nav-text">Fourth</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#First-two-weeks"><span class="nav-number">3.</span> <span class="nav-text">First two weeks</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#summarize-and-rewrite-some-data-augmentation-repo"><span class="nav-number">3.1.</span> <span class="nav-text">summarize and rewrite some data augmentation repo</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#simple-augmentation"><span class="nav-number">3.2.</span> <span class="nav-text">simple augmentation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#intensity-augment"><span class="nav-number">3.3.</span> <span class="nav-text">intensity augment</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Randomly-scale-and-shift-the-values-of-an-intensity-array，"><span class="nav-number">3.3.1.</span> <span class="nav-text">Randomly scale and shift the values of an intensity array，</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#similar-implementation"><span class="nav-number">3.3.2.</span> <span class="nav-text">similar implementation!</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ElasticAugment"><span class="nav-number">3.4.</span> <span class="nav-text">ElasticAugment</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DefectAugment"><span class="nav-number">3.5.</span> <span class="nav-text">DefectAugment</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#resources"><span class="nav-number">3.5.1.</span> <span class="nav-text">resources</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Model-test-and-redesign"><span class="nav-number">3.5.2.</span> <span class="nav-text">Model test and redesign</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Week-3"><span class="nav-number">4.</span> <span class="nav-text">Week 3</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#short-term-plan"><span class="nav-number">4.1.</span> <span class="nav-text">short term plan</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Model-improvement-and-training"><span class="nav-number">4.2.</span> <span class="nav-text">Model improvement and training</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#settings-and-training"><span class="nav-number">4.2.1.</span> <span class="nav-text">settings and training</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#training-settings"><span class="nav-number">4.2.1.1.</span> <span class="nav-text">training settings</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#create-envs"><span class="nav-number">4.2.1.1.1.</span> <span class="nav-text">create envs</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#training-parameter-setting"><span class="nav-number">4.2.1.1.2.</span> <span class="nav-text">training parameter setting</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Tensorboard-monitor-setting"><span class="nav-number">4.2.1.1.3.</span> <span class="nav-text">Tensorboard monitor setting</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#network-visualization"><span class="nav-number">4.2.2.</span> <span class="nav-text">network visualization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#model-structure-and-loss-function-improvement"><span class="nav-number">4.2.3.</span> <span class="nav-text">model structure and loss function improvement</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#dilated-CNN-block"><span class="nav-number">4.2.3.0.1.</span> <span class="nav-text">dilated CNN block</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#loss-function"><span class="nav-number">4.2.3.0.2.</span> <span class="nav-text">loss function</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Data-augmentation"><span class="nav-number">4.3.</span> <span class="nav-text">Data augmentation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#training"><span class="nav-number">4.3.1.</span> <span class="nav-text">training</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#train"><span class="nav-number">4.3.1.0.1.</span> <span class="nav-text">train</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#simple-augmentation-1"><span class="nav-number">4.3.1.1.</span> <span class="nav-text">simple augmentation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#intensity-augmentation"><span class="nav-number">4.3.1.2.</span> <span class="nav-text">intensity augmentation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#elastic-augmentation"><span class="nav-number">4.3.1.3.</span> <span class="nav-text">elastic augmentation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#defect-augmentation"><span class="nav-number">4.3.1.4.</span> <span class="nav-text">defect augmentation</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#test"><span class="nav-number">4.3.2.</span> <span class="nav-text">test</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#further-useful-augmentation"><span class="nav-number">4.3.3.</span> <span class="nav-text">further useful augmentation</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#future-work"><span class="nav-number">4.4.</span> <span class="nav-text">future work</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#compare-with-other-work-and-thoughs"><span class="nav-number">4.4.1.</span> <span class="nav-text">compare with other work and thoughs</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#future-plan"><span class="nav-number">4.4.2.</span> <span class="nav-text">future plan</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Week-4"><span class="nav-number">5.</span> <span class="nav-text">Week 4</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Loss-adjustment"><span class="nav-number">5.1.</span> <span class="nav-text">Loss adjustment</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Augmentation-improvement"><span class="nav-number">5.2.</span> <span class="nav-text">Augmentation improvement</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#deformation-augmentation"><span class="nav-number">5.2.1.</span> <span class="nav-text">deformation augmentation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#elastic-augmentation-1"><span class="nav-number">5.2.2.</span> <span class="nav-text">elastic augmentation</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#task2-reverse-predicting"><span class="nav-number">5.3.</span> <span class="nav-text">task2 reverse predicting</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Week-5-amp-6"><span class="nav-number">6.</span> <span class="nav-text">Week 5 &amp; 6</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#align-location-volume"><span class="nav-number">6.1.</span> <span class="nav-text">align location volume</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#data-augmentation"><span class="nav-number">6.1.1.</span> <span class="nav-text">data augmentation</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#loss-function-and-new-design"><span class="nav-number">6.2.</span> <span class="nav-text">loss function and new design</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Loss"><span class="nav-number">6.2.1.</span> <span class="nav-text">Loss</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#generalized-DICE-loss"><span class="nav-number">6.2.1.0.1.</span> <span class="nav-text">generalized DICE loss</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#reverse-prediction-and-deal-with-cracks"><span class="nav-number">6.3.</span> <span class="nav-text">reverse prediction and deal with cracks</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#对那两层做crack-align"><span class="nav-number">6.3.0.1.</span> <span class="nav-text">对那两层做crack align</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#for-predicted-data"><span class="nav-number">6.3.0.2.</span> <span class="nav-text">for predicted data:</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-6-reverse-all-predictions"><span class="nav-number">6.3.1.</span> <span class="nav-text">8.6 reverse all predictions</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#use-gt-syn-transformed，and-reverse，check-if-it-is-the-same-with-the-original-one"><span class="nav-number">6.3.1.1.</span> <span class="nav-text">use gt-syn transformed，and reverse，check if it is the same with the original one</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#A-in-15-and-48-layer-from-one-not-zero-do-reverse-crack"><span class="nav-number">6.3.1.2.</span> <span class="nav-text">A+: in 15 and 48 layer(from one, not zero), do reverse crack!</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Last-three-weeks"><span class="nav-number">7.</span> <span class="nav-text">Last three weeks</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#8-13"><span class="nav-number">7.1.</span> <span class="nav-text">8.13</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#8-29"><span class="nav-number">7.1.0.1.</span> <span class="nav-text">8.29</span></a></li></ol></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        
<div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">James Chen</span>

  
</div>



  <span class="post-meta-divider">|</span>




<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共196.4k字</span>
</div>


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/blog/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  



  


  <script type="text/javascript" src="/blog/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/blog/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/blog/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/blog/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/blog/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  












  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("klOjl0RBA8qP5IKgIXkOszBr-gzGzoHsz", "rCaN5wX4mjiRkRMzP95g7XHz");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  
  


  

  

  
</body>
</html>
